# PIPELINE DEFINITION
# Name: news-classification-pipeline
# Inputs:
#    bucket_name: str [Default: 'my-bucket']
#    data_path: str [Default: 'data.json']
#    error_analysis_out: str [Default: 'error_analysis']
#    eval_batch_size: int [Default: 200.0]
#    inference_batch_size: int [Default: 64.0]
#    model_path: str [Default: 'best_model.pt']
#    train_batch_size: int [Default: 32.0]
components:
  comp-error-analysis:
    executorLabel: exec-error-analysis
    inputDefinitions:
      parameters:
        bucket_name:
          parameterType: STRING
        data_path:
          parameterType: STRING
        out_path:
          parameterType: STRING
  comp-inference:
    executorLabel: exec-inference
    inputDefinitions:
      parameters:
        batch_size:
          parameterType: NUMBER_INTEGER
        bucket_name:
          parameterType: STRING
        model_path:
          parameterType: STRING
  comp-prepare-data:
    executorLabel: exec-prepare-data
    inputDefinitions:
      parameters:
        bucket_name:
          parameterType: STRING
        data_path:
          parameterType: STRING
  comp-train-model:
    executorLabel: exec-train-model
    inputDefinitions:
      parameters:
        bucket_name:
          parameterType: STRING
        eval_batch_size:
          parameterType: NUMBER_INTEGER
        train_batch_size:
          parameterType: NUMBER_INTEGER
deploymentSpec:
  executors:
    exec-error-analysis:
      container:
        args:
        - --bucket_name
        - '{{$.inputs.parameters[''bucket_name'']}}'
        - --data_path
        - '{{$.inputs.parameters[''data_path'']}}'
        - --out_path
        - '{{$.inputs.parameters[''out_path'']}}'
        command:
        - python3
        - error_analysis.py
        image: valeriy459/error-analysis:latest
    exec-inference:
      container:
        args:
        - --bucket_name
        - '{{$.inputs.parameters[''bucket_name'']}}'
        - --model_path
        - '{{$.inputs.parameters[''model_path'']}}'
        - --batch_size
        - '{{$.inputs.parameters[''batch_size'']}}'
        command:
        - python3
        - inference.py
        image: valeriy459/inference:latest
    exec-prepare-data:
      container:
        args:
        - --bucket_name
        - '{{$.inputs.parameters[''bucket_name'']}}'
        - --data_path
        - '{{$.inputs.parameters[''data_path'']}}'
        command:
        - python3
        - prepare_data.py
        image: valeriy459/prepare-data:latest
    exec-train-model:
      container:
        args:
        - --bucket_name
        - '{{$.inputs.parameters[''bucket_name'']}}'
        - --train_batch_size
        - '{{$.inputs.parameters[''train_batch_size'']}}'
        - --eval_batch_size
        - '{{$.inputs.parameters[''eval_batch_size'']}}'
        command:
        - python3
        - train_model.py
        image: valeriy459/train-model:latest
pipelineInfo:
  name: news-classification-pipeline
root:
  dag:
    tasks:
      error-analysis:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-error-analysis
        dependentTasks:
        - inference
        inputs:
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            data_path:
              componentInputParameter: data_path
            out_path:
              componentInputParameter: error_analysis_out
        taskInfo:
          name: error-analysis
      inference:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-inference
        dependentTasks:
        - train-model
        inputs:
          parameters:
            batch_size:
              componentInputParameter: inference_batch_size
            bucket_name:
              componentInputParameter: bucket_name
            model_path:
              componentInputParameter: model_path
        taskInfo:
          name: inference
      prepare-data:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-prepare-data
        inputs:
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            data_path:
              componentInputParameter: data_path
        taskInfo:
          name: prepare-data
      train-model:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-train-model
        dependentTasks:
        - prepare-data
        inputs:
          parameters:
            bucket_name:
              componentInputParameter: bucket_name
            eval_batch_size:
              componentInputParameter: eval_batch_size
            train_batch_size:
              componentInputParameter: train_batch_size
        taskInfo:
          name: train-model
  inputDefinitions:
    parameters:
      bucket_name:
        defaultValue: my-bucket
        isOptional: true
        parameterType: STRING
      data_path:
        defaultValue: data.json
        isOptional: true
        parameterType: STRING
      error_analysis_out:
        defaultValue: error_analysis
        isOptional: true
        parameterType: STRING
      eval_batch_size:
        defaultValue: 200.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      inference_batch_size:
        defaultValue: 64.0
        isOptional: true
        parameterType: NUMBER_INTEGER
      model_path:
        defaultValue: best_model.pt
        isOptional: true
        parameterType: STRING
      train_batch_size:
        defaultValue: 32.0
        isOptional: true
        parameterType: NUMBER_INTEGER
schemaVersion: 2.1.0
sdkVersion: kfp-2.11.0
