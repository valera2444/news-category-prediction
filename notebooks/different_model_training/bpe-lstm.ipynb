{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4243451,"sourceType":"datasetVersion","datasetId":32526},{"sourceId":10397748,"sourceType":"datasetVersion","datasetId":6442549}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"STATISTICA AMONG RUMS WILL BE COLLECTED IN CSV FILE\n\n\nMETRIC TRACKING WILL BE DONE ON TOP OF IT","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nstat_file = pd.DataFrame({'model':[],\n                  'model_params':[],\n                  'opt_params':[],\n                  'run_number':[],\n                  'epoch':[],\n                  'validation_or_train':[],\n                  'accuracy':[],\n                  'loss':[],\n                'additional_info':[]})\nstat_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:44:09.090615Z","iopub.execute_input":"2025-01-29T09:44:09.090896Z","iopub.status.idle":"2025-01-29T09:44:10.027722Z","shell.execute_reply.started":"2025-01-29T09:44:09.090869Z","shell.execute_reply":"2025-01-29T09:44:10.026904Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [model, model_params, opt_params, run_number, epoch, validation_or_train, accuracy, loss, additional_info]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>model_params</th>\n      <th>opt_params</th>\n      <th>run_number</th>\n      <th>epoch</th>\n      <th>validation_or_train</th>\n      <th>accuracy</th>\n      <th>loss</th>\n      <th>additional_info</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:44:11.812710Z","iopub.execute_input":"2025-01-29T09:44:11.813109Z","iopub.status.idle":"2025-01-29T09:44:11.823942Z","shell.execute_reply.started":"2025-01-29T09:44:11.813071Z","shell.execute_reply":"2025-01-29T09:44:11.823115Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset\nimport re \nclass NewsDataset(Dataset):\n\n    def __preprocess(self, data):\n        data = data.fillna('absent')\n        \n        data.headline[data['headline'].apply(len) == 0] = 'absent'\n        data.link[data['link'].apply(len) == 0] = 'absent'\n        data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n        data.authors[data['authors'].apply(len) == 0] = 'absent'\n        return data\n        \n    def __init__(self, path):\n        \"\"\"_summary_\n\n        Args:\n            path (str): path to .json file\n        \"\"\"\n        j=pd.read_json(path, lines=True)\n        j=self.__preprocess(j)\n        \n        link = j['link'].str.lower().replace(r'\\b(www|http|https|com|html)\\b',' ', regex=True)\n\n        \n        link = link.apply(lambda l: re.sub('[^a-z A-Z 0-9]+', ' ',l ))\n\n        \n        self.x = 'headline: ' +  j['headline'] + \\\n        ' ; short_description: ' + j['short_description'] + \\\n        ' ; authors: ' + j['authors'] + \\\n        ' ; link: ' + link\n\n        \n        self.y = j['category'].astype('category').cat.codes\n        \n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        \"\"\"\n\n        Args:\n            idx (list): _description_\n\n        Returns:\n            str: single item\n        \"\"\"\n        return {'x':self.x.iloc[idx],'y':self.y.iloc[idx]}\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:44:12.033843Z","iopub.execute_input":"2025-01-29T09:44:12.034183Z","iopub.status.idle":"2025-01-29T09:44:15.090107Z","shell.execute_reply.started":"2025-01-29T09:44:12.034152Z","shell.execute_reply":"2025-01-29T09:44:15.089412Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport math\n\nclass BertEmbeddings(nn.Module):\n    def __init__(self, vocab_size, hidden_size, context_length):\n        super().__init__()\n        self.word_embeddings = nn.Embedding(vocab_size, hidden_size, padding_idx=0)\n        self.position_embeddings = nn.Embedding(context_length, hidden_size)\n        self.token_type_embeddings = nn.Embedding(2, hidden_size)\n\n    def forward(self, input_ids, token_type_ids):\n        seq_length = input_ids.size(1)\n        position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)\n        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n\n        words_embeddings = self.word_embeddings(input_ids)\n        position_embeddings = self.position_embeddings(position_ids)\n        token_type_embeddings = self.token_type_embeddings(token_type_ids)\n\n        embeddings = words_embeddings + position_embeddings + token_type_embeddings\n        return embeddings\n\n\nclass LayerNorm(nn.Module):\n    def __init__(self, normalized_shape,  eps=0.00001):\n        super().__init__()\n        self.eps=eps\n        self.normalized_shape=normalized_shape\n        self.gamma = nn.Parameter(torch.ones((1,1,self.normalized_shape)), requires_grad=True)\n        self.beta = nn.Parameter(torch.zeros((1,1,self.normalized_shape)), requires_grad=True)\n\n    def forward(self, input):\n        \"\"\"\n\n        Args:\n            input (torch.Tensor): (B, T, C)\n\n        Returns:\n            torch.Tensor: (B, T, C)\n        \"\"\"\n        mean = torch.mean(input, dim=-1, keepdim=True)\n        var = torch.var(input, dim=-1, keepdim=True,  unbiased=False)\n        \n        out = (input - mean) / torch.sqrt(var+self.eps) * self.gamma + self.beta\n        \n        return out\n\n\nclass MultiHeadAttention(nn.Module):\n\n    def __init__(self, model_dim, n_heads, p_dropout = 0.0):\n\n        super().__init__()\n        assert model_dim % n_heads == 0\n        \n        self.dim = model_dim \n        self.n_heads=n_heads\n        self.head_dim = self.dim // self.n_heads\n        \n\n        self.qkv = nn.Linear(model_dim, 3 * model_dim, bias=True)\n\n        self.dropout = nn.Dropout(p=p_dropout)\n\n        self.proj = nn.Linear(model_dim, model_dim, bias=True)#part of attention\n\n        \n\n    def forward(self, input, attn_mask):\n        \"\"\"_summary_\n\n        Args:\n            input (torch.tensor): (B,T,C)\n            attn_mask (torch.tensor): (B,T)\n\n        Returns:\n            _type_: _description_\n        \"\"\"\n\n        #Mutihead attention\n        qkv = self.qkv(input) # фееутешщт ьфыл шт иуке(B, T, 3*dim)\n        q, k, v = torch.chunk(qkv, 3, dim=-1)\n    \n        q = q.view(input.size(0), input.size(1), self.n_heads, self.head_dim).transpose(1, 2)  # (B, n_heads, T, head_dim)\n        k = k.view(input.size(0), input.size(1), self.n_heads, self.head_dim).transpose(1, 2)  # (B, n_heads, T, head_dim)\n        v = v.view(input.size(0), input.size(1), self.n_heads, self.head_dim).transpose(1, 2)  # (B, n_heads, T, head_dim)\n\n        weights = q @ k.transpose(-2,-1) * self.head_dim**(-0.5) # (B,n_heads, T , T)\n\n        \n        weights = weights.masked_fill(attn_mask.unsqueeze(1).unsqueeze(2) == 0, -torch.inf)\n        \n        weights = torch.nn.functional.softmax (weights, dim=3)\n\n        weights = self.dropout(weights)\n        \n        out = weights @ v\n        \n        out=out.transpose(1,2) # (B,T, n_heads , head_dim)\n        \n        #Concatenation of heads\n        out = out.reshape(out.size(0), out.size(1),-1) # (B,T, C)\n        out = self.proj(out)\n\n        return out\n\n\nclass TransfomerBlock(nn.Module):\n\n    def __init__(self, model_dim, n_heads, max_seq_len, p_dropout = 0.0):\n\n        super().__init__()\n        assert model_dim % n_heads == 0\n        \n        self.dim = model_dim \n        self.n_heads=n_heads\n        self.head_dim = self.dim // self.n_heads\n        \n\n        self.mha = MultiHeadAttention(model_dim, n_heads, max_seq_len)\n\n        self.ln1 = LayerNorm(model_dim)\n\n        self.dropout= nn.Dropout(p=p_dropout)\n\n        self.mlp = nn.Sequential(nn.Linear(model_dim, 4*model_dim),\n                                 nn.GELU(),\n                                 nn.Linear(4*model_dim, model_dim),\n                                 )\n        \n        self.ln2 = LayerNorm(model_dim)\n\n\n    def forward(self, input, mask):\n        \"\"\"_summary_\n\n        Args:\n            input (torch.tensor): input for block with dimensions: (B, T, C), where B - batch, T - sequence length, C - model size\n            mask (torch.tensor): (B, T)\n        Returns:\n            Next tokens for each k-gram. Shape : # (B,T, C)\n        \"\"\"\n        residual_1 = input\n        \n        #Mutihead attention\n        out = self.mha (input, mask)\n\n        out = self.ln1 (out)\n\n        out = self.dropout(out)\n        #Add\n        out = residual_1 + out\n\n        residual_2 = out\n        \n        #Feed forward\n        out = self.mlp (out)\n\n        out = self.ln2(out)\n\n        out = self.dropout(out)\n        #Add\n        out = residual_2 + out\n        \n\n\n        return out\n\n\n\nclass Transformer(nn.Module):\n    \"\"\"\n    Encoder-only transofrmer.\n    forward method takes sequences with the same lengthes as input, and then attention mask applied for pad tokens\n    \"\"\"\n        \n    def __init__(self, vocab_size, model_dim, n_heads, max_seq_len, n_blocks, p_dropout=0.0):\n        super().__init__()\n        self.vocab_size, self.model_dim, self.n_heads, self.max_seq_len, self.n_blocks = vocab_size, model_dim, n_heads, max_seq_len, n_blocks\n        self.emb  = BertEmbeddings(vocab_size, model_dim,max_seq_len)\n        self.emb_ln = LayerNorm(model_dim)\n        self.dropout = nn.Dropout(p=p_dropout)\n        self.net = nn.ModuleList([TransfomerBlock(model_dim, n_heads,p_dropout) for _ in range (n_blocks)])\n       \n        self.final_linear = nn.Linear(model_dim, model_dim)\n        self.activation = nn.Tanh()\n\n\n    def forward(self, input, attn_mask, token_type_ids):\n        \"\"\"\n        input (torch.Tensor): batch of data to predict logits on. (B, T, C)\n        Args:\n            input (torch.Tensor): batch of data to predict logits on. (B, T, C)\n            attn_mask (torch.Tensor): pad tokens indicator. (B, T)\n        Returns:\n            torch.Tensor: Tensors with logits. nan where pad token. (B, T, vocab_size) - mlm_logits, (B, 2)- nsp logits\n        \"\"\"\n        \n        embs = self.emb(input, token_type_ids)\n\n        embs = self.emb_ln (embs)\n\n        embs = self.dropout(embs)\n\n        for encoder in self.net:\n            embs = encoder.forward(embs, attn_mask)\n\n        hidden = embs\n\n        out = self.final_linear(embs)#(B, T, C)\n\n        out = self.activation(out)\n\n        return hidden, out\n    \n\nclass BertPooler(nn.Module):\n        def __init__(self, model_dim):\n            super().__init__()\n            self.dense = nn.Linear(model_dim, model_dim)\n            self.activation = nn.Tanh()\n\n        def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n            # We \"pool\" the model by simply taking the hidden state corresponding\n            # to the first token.\n            first_token_tensor = hidden_states[:, 0, :]\n            #print(first_token_tensor.shape)\n            pooled_output = self.dense(first_token_tensor)\n            pooled_output = self.activation(pooled_output)\n            return pooled_output\n        \nclass CustomBertForClassification(nn.Module):\n\n\n    \n        \n    def __init__(self, bert_base, hidden_dim, num_labels):\n\n        super().__init__()\n        self.bert_base = bert_base\n        self.hidden_dim = hidden_dim\n        self.num_labels=num_labels\n        self.pooler = BertPooler(bert_base.model_dim)\n        self.classification_head = nn.Sequential(nn.Linear(bert_base.model_dim,hidden_dim ),\n                                                 nn.ReLU(),\n                                                 nn.Linear(hidden_dim, num_labels))\n        \n        \n    def forward(self, input, attn_mask, token_type_ids):\n        \"\"\"_summary_\n\n        Args:\n            input (_type_): _description_\n            attn_mask (_type_): _description_\n            token_type_ids (_type_): _description_\n\n        Returns:\n            torch.Tensor: logits for num_labels classes\n        \"\"\"\n\n        hidden, out = self.bert_base(input, attn_mask, token_type_ids)\n        #print(out.shape)\n        out=self.pooler(hidden)#Must be applied on hidden state\n        out = self.classification_head(out)\n        return out\n\nimport torch\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n\nfrom transformers import BertModel\nimport torch\n\ndef create_bert_for_classificatoin():\n    t = Transformer(vocab_size=tokenizer.vocab_size, model_dim=768,n_heads=12,max_seq_len=512,n_blocks=12)\n    model = BertModel.from_pretrained(\"bert-base-uncased\", torch_dtype=torch.float16, attn_implementation=\"sdpa\")\n    \n    \n    # Function to load weights from base BERT into the custom model\n    def load_custom_model_weights(base_model, custom_model):\n        custom_model_state_dict = custom_model.state_dict()\n        base_model_state_dict = base_model.state_dict()\n    \n        # Mapping for the embedding layers\n        mapping = {\n            \"emb.word_embeddings.weight\": \"embeddings.word_embeddings.weight\",\n            \"emb.position_embeddings.weight\": \"embeddings.position_embeddings.weight\",\n            \"emb.token_type_embeddings.weight\": \"embeddings.token_type_embeddings.weight\",\n            \"emb_ln.gamma\": \"embeddings.LayerNorm.weight\",\n            \"emb_ln.beta\": \"embeddings.LayerNorm.bias\"\n        }\n    \n        # Mapping for the encoder layers\n        for i in range(12):  # Loop through the 12 transformer layers\n            mapping.update({\n                f\"net.{i}.mha.qkv.weight\": [\n                    f\"encoder.layer.{i}.attention.self.query.weight\",\n                    f\"encoder.layer.{i}.attention.self.key.weight\",\n                    f\"encoder.layer.{i}.attention.self.value.weight\"\n                ],\n                f\"net.{i}.mha.qkv.bias\": [\n                    f\"encoder.layer.{i}.attention.self.query.bias\",\n                    f\"encoder.layer.{i}.attention.self.key.bias\",\n                    f\"encoder.layer.{i}.attention.self.value.bias\"\n                ],\n                f\"net.{i}.mha.proj.weight\": f\"encoder.layer.{i}.attention.output.dense.weight\",\n                f\"net.{i}.mha.proj.bias\": f\"encoder.layer.{i}.attention.output.dense.bias\",\n                f\"net.{i}.ln1.gamma\": f\"encoder.layer.{i}.attention.output.LayerNorm.weight\",\n                f\"net.{i}.ln1.beta\": f\"encoder.layer.{i}.attention.output.LayerNorm.bias\",\n                f\"net.{i}.mlp.0.weight\": f\"encoder.layer.{i}.intermediate.dense.weight\",\n                f\"net.{i}.mlp.0.bias\": f\"encoder.layer.{i}.intermediate.dense.bias\",\n                f\"net.{i}.mlp.2.weight\": f\"encoder.layer.{i}.output.dense.weight\",\n                f\"net.{i}.mlp.2.bias\": f\"encoder.layer.{i}.output.dense.bias\",\n                f\"net.{i}.ln2.gamma\": f\"encoder.layer.{i}.output.LayerNorm.weight\",\n                f\"net.{i}.ln2.beta\": f\"encoder.layer.{i}.output.LayerNorm.bias\"\n            })\n    \n        # Mapping for the final pooler layer\n        mapping.update({\n            \"final_linear.weight\": \"pooler.dense.weight\",\n            \"final_linear.bias\": \"pooler.dense.bias\"\n        })\n    \n        # Copy the weights\n        for custom_param, base_param in mapping.items():\n            if isinstance(base_param, list):  # Handle combined qkv weights and biases\n                qkv_weight = torch.cat([\n                    base_model_state_dict[base_param[0]],\n                    base_model_state_dict[base_param[1]],\n                    base_model_state_dict[base_param[2]]\n                ], dim=0)\n                custom_model_state_dict[custom_param].copy_(qkv_weight)\n            else:\n                custom_model_state_dict[custom_param].copy_(base_model_state_dict[base_param])\n    \n        custom_model.load_state_dict(custom_model_state_dict)\n        print(\"Weights successfully loaded from base model into custom model.\")\n    \n    load_custom_model_weights(model, t)\n    \n    classification_bert = CustomBertForClassification(t, 1024, 42)\n    \n    classification_bert\n\n    return classification_bert\n\n","metadata":{"execution":{"iopub.status.busy":"2025-01-29T09:44:15.091231Z","iopub.execute_input":"2025-01-29T09:44:15.091686Z","iopub.status.idle":"2025-01-29T09:44:32.921873Z","shell.execute_reply.started":"2025-01-29T09:44:15.091655Z","shell.execute_reply":"2025-01-29T09:44:32.921162Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f561d93523d42819160ff0fcfb80f07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589121eb67914b93947472cfd16a15f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"876db8e186204da98e134e06a836855f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db1f15d566af435baa4894951387a0a3"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"class LSTMForClassificatoin(nn.Module):\n    def __init__(self,vocab_size, emb_dim,bidirectional,  hidden_size_lstm, num_layers, hiddem_size_MLP, num_classes):\n        super().__init__()\n        self.bidirectional = bidirectional\n        self.embs = nn.Embedding(vocab_size, emb_dim)\n        self.lstm = nn.LSTM(emb_dim, hidden_size_lstm, num_layers, batch_first=True,bidirectional=bidirectional)\n        if bidirectional:\n            self.linear_up = nn.Linear(hidden_size_lstm * 2, hiddem_size_MLP)\n        else:\n            self.linear_up = nn.Linear(hidden_size_lstm, hiddem_size_MLP)\n        self.activation = nn.ReLU()\n        self.linear_down = nn.Linear(hiddem_size_MLP, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        x - batched tokens\n        Reurns:\n            logits for classes\n        \"\"\"\n        emb = self.embs(x)\n        output, _ = self.lstm(emb)\n        if self.bidirectional:\n            lin1 = self.linear_up(output[:,-1,:] + output[:,0,:] )\n        else:\n            lin1 = self.linear_up(output[:,-1,:] )\n        lin1 = self.activation(lin1)\n        out = self.linear_down(lin1)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T10:41:44.602189Z","iopub.execute_input":"2025-01-29T10:41:44.602474Z","iopub.status.idle":"2025-01-29T10:41:44.608468Z","shell.execute_reply.started":"2025-01-29T10:41:44.602451Z","shell.execute_reply":"2025-01-29T10:41:44.607731Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"train_batch_size=32\neval_batch_size = 200\naccumulation_steps = 150\n\ntrain_test_split = [0.8, 0.2]\nval_test_split = [0.5, 0.5]\nepochs = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:44:32.930294Z","iopub.execute_input":"2025-01-29T09:44:32.930594Z","iopub.status.idle":"2025-01-29T09:44:32.965580Z","shell.execute_reply.started":"2025-01-29T09:44:32.930564Z","shell.execute_reply":"2025-01-29T09:44:32.964781Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader\nds = NewsDataset('/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json')\nfrom torch.utils.data import Dataset, DataLoader\ngenerator = torch.Generator().manual_seed(42)\ntrain_data, test_data = torch.utils.data.random_split(ds, train_test_split,generator=generator)\nval_data, test_data = torch.utils.data.random_split(test_data, val_test_split,generator=generator)\n\ntrain_dataloader = DataLoader(train_data, batch_size=train_batch_size,\n                        shuffle=True, num_workers=0)\nval_dataloader = DataLoader(val_data, batch_size=eval_batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2025-01-29T10:14:00.564497Z","iopub.execute_input":"2025-01-29T10:14:00.564831Z","iopub.status.idle":"2025-01-29T10:14:04.533850Z","shell.execute_reply.started":"2025-01-29T10:14:00.564808Z","shell.execute_reply":"2025-01-29T10:14:04.533124Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-3-baa2275c0bce>:10: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.headline[data['headline'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:10: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.headline[data['headline'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.link[data['link'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.link[data['link'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.authors[data['authors'].apply(len) == 0] = 'absent'\n<ipython-input-3-baa2275c0bce>:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.authors[data['authors'].apply(len) == 0] = 'absent'\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"print('total samples:', len(ds))\nprint('train samples:', len(train_data))\nprint('test samples:', len(test_data))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T09:44:38.158199Z","iopub.execute_input":"2025-01-29T09:44:38.158447Z","iopub.status.idle":"2025-01-29T09:44:38.163758Z","shell.execute_reply.started":"2025-01-29T09:44:38.158417Z","shell.execute_reply":"2025-01-29T09:44:38.163002Z"}},"outputs":[{"name":"stdout","text":"total samples: 209527\ntrain samples: 167622\ntest samples: 20952\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"device = 'cuda:0'if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2025-01-29T09:44:38.165762Z","iopub.execute_input":"2025-01-29T09:44:38.165994Z","iopub.status.idle":"2025-01-29T09:44:38.227074Z","shell.execute_reply.started":"2025-01-29T09:44:38.165975Z","shell.execute_reply":"2025-01-29T09:44:38.226306Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'cuda:0'"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.named_parameters()):\n        nn=1\n        for s in list(p[1].size()):\n            nn = nn*s\n        pp += nn\n        print(p[0])\n        print(nn)\n    return pp","metadata":{"execution":{"iopub.status.busy":"2025-01-29T09:44:38.228230Z","iopub.execute_input":"2025-01-29T09:44:38.228491Z","iopub.status.idle":"2025-01-29T09:44:38.242488Z","shell.execute_reply.started":"2025-01-29T09:44:38.228470Z","shell.execute_reply":"2025-01-29T09:44:38.241806Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def evaluate(model, test_dataloader):\n    with torch.no_grad():\n            matches=0\n            number_of_iters = 0\n            for b_eval in test_dataloader:\n                tokenized = tokenizer(b_eval['x'], padding=True, return_tensors=\"pt\")\n                tokenized.to(device)\n                ids, mask, token_type_ids = tokenized['input_ids'], tokenized['attention_mask'], tokenized['token_type_ids']\n                preds = model(ids)\n                loss = criterion(preds, b_eval['y'].long().to(device))\n                matches += torch.sum(torch.isclose(b_eval['y'].long().to(device), torch.argmax(preds, dim=1)))\n\n            accuracy = matches / len(test_dataloader.dataset)\n            print('accuracy: ', accuracy, 'loss',loss)\n    return accuracy, loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T10:41:50.555137Z","iopub.execute_input":"2025-01-29T10:41:50.555422Z","iopub.status.idle":"2025-01-29T10:41:50.560902Z","shell.execute_reply.started":"2025-01-29T10:41:50.555399Z","shell.execute_reply":"2025-01-29T10:41:50.560004Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"LRs=[]\nepoch_loss = []\nepoch_acc_train=[]\nepoch_acc_test=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T10:41:50.894809Z","iopub.execute_input":"2025-01-29T10:41:50.895148Z","iopub.status.idle":"2025-01-29T10:41:50.898671Z","shell.execute_reply.started":"2025-01-29T10:41:50.895120Z","shell.execute_reply":"2025-01-29T10:41:50.897860Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_params = {'vocab_size':30522,\n              'emb_dim':768,\n              'hidden_size_lstm':256,\n              'num_layers':3,\n               'hiddem_size_MLP':1024,\n               'num_classes':42,\n               'bidirectional':True}\nmodel = LSTMForClassificatoin(vocab_size=model_params['vocab_size'],\n                          emb_dim=model_params['emb_dim'],\n                          hidden_size_lstm=model_params['hidden_size_lstm'],\n                          num_layers=model_params['num_layers'],\n                          hiddem_size_MLP=model_params['hiddem_size_MLP'],\n                          num_classes=model_params['num_classes'],\n                          bidirectional=model_params['bidirectional'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:22.034441Z","iopub.execute_input":"2025-01-29T11:59:22.034740Z","iopub.status.idle":"2025-01-29T11:59:22.271363Z","shell.execute_reply.started":"2025-01-29T11:59:22.034716Z","shell.execute_reply":"2025-01-29T11:59:22.270724Z"}},"outputs":[],"execution_count":89},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bert = create_bert_for_classificatoin()\nmodel.embs.weight = bert.bert_base.emb.word_embeddings.weight","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:23.827139Z","iopub.execute_input":"2025-01-29T11:59:23.827456Z","iopub.status.idle":"2025-01-29T11:59:24.960281Z","shell.execute_reply.started":"2025-01-29T11:59:23.827426Z","shell.execute_reply":"2025-01-29T11:59:24.959539Z"}},"outputs":[{"name":"stdout","text":"Weights successfully loaded from base model into custom model.\n","output_type":"stream"}],"execution_count":90},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:25.086291Z","iopub.execute_input":"2025-01-29T11:59:25.086583Z","iopub.status.idle":"2025-01-29T11:59:25.130075Z","shell.execute_reply.started":"2025-01-29T11:59:25.086527Z","shell.execute_reply":"2025-01-29T11:59:25.129255Z"}},"outputs":[{"execution_count":91,"output_type":"execute_result","data":{"text/plain":"LSTMForClassificatoin(\n  (embs): Embedding(30522, 768)\n  (lstm): LSTM(768, 256, num_layers=3, batch_first=True, bidirectional=True)\n  (linear_up): Linear(in_features=512, out_features=1024, bias=True)\n  (activation): ReLU()\n  (linear_down): Linear(in_features=1024, out_features=42, bias=True)\n)"},"metadata":{}}],"execution_count":91},{"cell_type":"code","source":"def insert_row(df, row):\n    return pd.concat([df, row], ignore_index=True)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:26.501839Z","iopub.execute_input":"2025-01-29T11:59:26.502113Z","iopub.status.idle":"2025-01-29T11:59:26.505821Z","shell.execute_reply.started":"2025-01-29T11:59:26.502092Z","shell.execute_reply":"2025-01-29T11:59:26.505038Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"run_number=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:27.370399Z","iopub.execute_input":"2025-01-29T11:59:27.370752Z","iopub.status.idle":"2025-01-29T11:59:27.374445Z","shell.execute_reply.started":"2025-01-29T11:59:27.370721Z","shell.execute_reply":"2025-01-29T11:59:27.373525Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"run_number+=1\ndef train(model, epochs, optimizer, criterion, scheduler, callback, callback_freq, additional_info):\n    global stat_file\n    for epoch_num in range(1,epochs):\n        \n        accuracies_test=  []\n        accuracies_train=  []\n        losses=[]\n        \n        ttl_loss=0\n        train_iters=0\n        for i, train_batch in enumerate(train_dataloader):\n            \n            # Tokenize and pad\n            tokenized = tokenizer(train_batch['x'], padding=True, return_tensors=\"pt\")\n            tokenized.to(device)\n        \n            # Create tensor for input batch\n            ids, mask, token_type_ids = tokenized['input_ids'], tokenized['attention_mask'], tokenized['token_type_ids']\n            preds = model(ids)\n            loss = criterion(preds, train_batch['y'].long().to(device))\n            \n            ttl_loss+=loss.item()\n            train_iters+=1\n            \n            loss.backward()\n            \n            \n            if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n                optimizer.step()                            # Now we can do an optimizer step\n                model.zero_grad()\n                \n                print('loss', ttl_loss / train_iters)\n                losses.append(ttl_loss / train_iters)\n            \n                \n                ttl_loss=0\n                train_iters=0\n                \n                \n                train_accuracy = torch.sum(torch.isclose(train_batch['y'].long().to(device), torch.argmax(preds, dim=1))) / train_batch_size\n                accuracies_train.append(train_accuracy)\n                print('train accuracy: ',train_accuracy )\n                \n                row = {'model': model.__class__,\n                  'model_params':str(model_params),\n                  'opt_params':str(optimizer_params),\n                  'run_number':run_number,\n                  'epoch':epoch_num,\n                  'validation_or_train':'train',\n                  'accuracy':train_accuracy,\n                  'loss':losses[-1],\n                    'additional_info':additional_info}\n\n                stat_file = insert_row(stat_file, pd.DataFrame(row, index=[len(stat_file)]))\n                \n            del preds\n            del tokenized\n            del loss\n    \n        scheduler.step()\n        \n        print('epoch ',str(epoch_num),'lr', scheduler.get_last_lr())\n        LRs.append(scheduler.get_last_lr())\n\n        if epoch_num % callback_freq == 0:\n            val_acc, loss_val = callback(model, val_dataloader)\n            epoch_acc_test.append(val_acc)\n            print('accuracy: ', val_acc)\n            row = {'model': model.__class__,\n                  'model_params':str(model_params),\n                  'opt_params':str(optimizer_params),\n                  'run_number':run_number,\n                  'epoch':epoch_num,\n                  'validation_or_train':'validation',\n                  'accuracy':val_acc,\n                  'loss':loss_val,\n                  'additional_info':additional_info}\n\n            stat_file = insert_row(stat_file, pd.DataFrame(row, index=[len(stat_file)]))\n        \n        \n        epoch_acc_train.append(accuracies_train)\n        epoch_loss.append(losses)\n        torch.save(model.state_dict(), 'weights'+str(epoch_num)+str(model.__class__)+'.pt')\n\n    return stat_file","metadata":{"execution":{"iopub.status.busy":"2025-01-29T11:59:27.830131Z","iopub.execute_input":"2025-01-29T11:59:27.830486Z","iopub.status.idle":"2025-01-29T11:59:27.840616Z","shell.execute_reply.started":"2025-01-29T11:59:27.830456Z","shell.execute_reply":"2025-01-29T11:59:27.839641Z"},"trusted":true},"outputs":[],"execution_count":94},{"cell_type":"code","source":"optimizer_params = {'lr':0.00035, 'step_size':10, 'gamma':0.1}\ncallback_freq = 1\nepochs = 20\noptimizer = torch.optim.Adam(model.parameters(), lr=optimizer_params['lr'])\ncriterion = nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                            step_size=optimizer_params['step_size'],\n                                            gamma=optimizer_params['gamma'])\n\n\ntrain(model=model,\n      epochs=epochs,\n      optimizer=optimizer,\n      criterion=criterion,\n      scheduler=scheduler,\n      callback=evaluate,\n      callback_freq=1,\n     additional_info='bert embeddings pretrained ; not frozen')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T11:59:35.985434Z","iopub.execute_input":"2025-01-29T11:59:35.985757Z","iopub.status.idle":"2025-01-29T12:32:30.747080Z","shell.execute_reply.started":"2025-01-29T11:59:35.985720Z","shell.execute_reply":"2025-01-29T12:32:30.745968Z"}},"outputs":[{"name":"stdout","text":"loss 3.738717573483785\ntrain accuracy:  tensor(0.0312, device='cuda:0')\nloss 3.7227306350072227\ntrain accuracy:  tensor(0.0625, device='cuda:0')\nloss 3.7067727343241375\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.689597611427307\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.6674870093663534\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.638439734776815\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.5974760548273723\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.5378620862960815\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.4551806116104125\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 3.3622903378804523\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 3.3535592365264892\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.377250428199768\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.3489578342437745\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.294418520927429\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2918902095158895\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.3150304810206097\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.319513160387675\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.3327826086680092\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.3234162950515747\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.325135270754496\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.2873024129867554\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.2892081117630005\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2831415621439617\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.314199455579122\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.251938048998515\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.291355045636495\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.314175182978312\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2725640885035197\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.281353030204773\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.2925846115748088\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.2965450541178387\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.277514761288961\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2876567713419598\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.2989045842488607\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nepoch  1 lr [0.00035]\naccuracy:  tensor(0.1669, device='cuda:0') loss tensor(3.2707, device='cuda:0')\naccuracy:  tensor(0.1669, device='cuda:0')\nloss 3.2993209314346315\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.2722930669784547\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.309444705645243\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 3.282062301635742\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.275385104815165\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.27667290687561\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 3.2569095993041994\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.3095962826410927\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2909774669011433\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 3.272949948310852\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.2437027994791667\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.2650983047485354\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.3100685850779215\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 3.276371504465739\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.295104964574178\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.2840585708618164\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.264648946126302\ntrain accuracy:  tensor(0.0625, device='cuda:0')\nloss 3.27319167137146\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.269095597267151\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.299025444984436\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.2773376178741453\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 3.233381756146749\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.2662647072474162\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.258799432118734\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.2623473246892294\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.244230194091797\ntrain accuracy:  tensor(0.0312, device='cuda:0')\nloss 3.2231893825531004\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.2124798583984373\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.1819230858484904\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 3.178903252283732\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.1742960341771442\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.1361037063598634\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.1458601490656535\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.153852653503418\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nepoch  2 lr [0.00035]\naccuracy:  tensor(0.1669, device='cuda:0') loss tensor(3.1278, device='cuda:0')\naccuracy:  tensor(0.1669, device='cuda:0')\nloss 3.139241862297058\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.1959131288528444\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.1226865418752037\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.152508192062378\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.126640682220459\ntrain accuracy:  tensor(0.0938, device='cuda:0')\nloss 3.0944380633036297\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.117419023513794\ntrain accuracy:  tensor(0.0625, device='cuda:0')\nloss 3.1401313384373983\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 3.0708360195159914\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.0757714160283407\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.0789801756540935\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 3.096140127182007\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.046810652414958\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.0778777170181275\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.0462559922536214\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 3.0995451672871908\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.057319084803263\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.051555452346802\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.0296908378601075\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.022622323036194\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 3.0031366030375164\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 3.0002973238627115\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 3.010354684193929\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.031936701138814\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.9718607378005983\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 3.0269007364908855\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 3.003865450223287\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 2.9778250964482624\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.9504674847920738\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.963550033569336\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.9636053450902304\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 2.940864052772522\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.898658928871155\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.9507773160934447\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nepoch  3 lr [0.00035]\naccuracy:  tensor(0.2237, device='cuda:0') loss tensor(3.1062, device='cuda:0')\naccuracy:  tensor(0.2237, device='cuda:0')\nloss 2.9081222597757974\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.9116329971949257\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.888198920885722\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.9054812145233155\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.884080826441447\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.900749190648397\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.838182530403137\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.8669372685750325\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.837568286259969\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.841914340655009\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.786194869677226\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.738203365802765\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 2.8149691247940063\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.8167619132995605\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.794307610193888\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.814298637708028\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.7674949073791506\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.799917677243551\ntrain accuracy:  tensor(0.1250, device='cuda:0')\nloss 2.7597519318262735\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.8050418949127196\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.7361558373769124\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.7138196134567263\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.709349816640218\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.6821145677566527\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.651893951098124\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.688830925623576\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.6451308059692384\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.6872724318504333\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.625648816426595\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.5421154475212098\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.5815211749076843\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.528934473991394\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.4765237402915954\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.490417675177256\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nepoch  4 lr [0.00035]\naccuracy:  tensor(0.3043, device='cuda:0') loss tensor(2.5329, device='cuda:0')\naccuracy:  tensor(0.3043, device='cuda:0')\nloss 2.4737649663289387\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.5003144764900207\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.4434409523010254\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.469615527788798\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.411931597391764\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.437046701113383\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.422327275276184\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3696565278371176\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.389723734060923\ntrain accuracy:  tensor(0.5000, device='cuda:0')\nloss 2.3826203123728433\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.3896243945757547\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.4066270271937054\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.3757026664415997\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.4457836445172627\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.4718846186002095\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.413533180554708\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.430232773621877\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.445076036453247\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.4004119126001995\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.425147310098012\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.4857913398742677\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.386618804136912\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.3965713357925416\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.4514227024714152\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.409174788792928\ntrain accuracy:  tensor(0.4688, device='cuda:0')\nloss 2.381861673196157\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.3699787839253745\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.342521934509277\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3851459566752116\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.3625111746788026\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.325954339504242\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.328318405151367\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nloss 2.340964086850484\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.319956784248352\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nepoch  5 lr [0.00035]\naccuracy:  tensor(0.3282, device='cuda:0') loss tensor(2.2489, device='cuda:0')\naccuracy:  tensor(0.3282, device='cuda:0')\nloss 2.313034411271413\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3043384186426796\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3362394309043886\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.3226113216082256\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.325821781158447\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3315860764185588\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.3059470121065777\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.3975272130966188\ntrain accuracy:  tensor(0.3438, device='cuda:0')\nloss 2.283235143025716\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.3888925035794575\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.293531645933787\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.379590755303701\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.328001184463501\ntrain accuracy:  tensor(0.4688, device='cuda:0')\nloss 2.3208992012341816\ntrain accuracy:  tensor(0.4688, device='cuda:0')\nloss 2.2989922642707823\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.2799134270350137\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.3300986385345457\ntrain accuracy:  tensor(0.2500, device='cuda:0')\nloss 2.2406896273295085\ntrain accuracy:  tensor(0.2188, device='cuda:0')\nloss 2.2810930808385215\ntrain accuracy:  tensor(0.1875, device='cuda:0')\nloss 2.233379124800364\ntrain accuracy:  tensor(0.5312, device='cuda:0')\nloss 2.250320222377777\ntrain accuracy:  tensor(0.4688, device='cuda:0')\nloss 2.3006012145678203\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.2572739005088804\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.255099030335744\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.2471778440475463\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.239543035030365\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.2620589486757914\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.234152251879374\ntrain accuracy:  tensor(0.3125, device='cuda:0')\nloss 2.283167426586151\ntrain accuracy:  tensor(0.1562, device='cuda:0')\nloss 2.2717578824361166\ntrain accuracy:  tensor(0.3750, device='cuda:0')\nloss 2.2436030650138856\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.236715867519379\ntrain accuracy:  tensor(0.4375, device='cuda:0')\nloss 2.250096845626831\ntrain accuracy:  tensor(0.4062, device='cuda:0')\nloss 2.2485601751009625\ntrain accuracy:  tensor(0.2812, device='cuda:0')\nepoch  6 lr [0.00035]\naccuracy:  tensor(0.3512, device='cuda:0') loss tensor(2.2901, device='cuda:0')\naccuracy:  tensor(0.3512, device='cuda:0')\nloss 2.2336742091178894\ntrain accuracy:  tensor(0.4375, device='cuda:0')\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-95-c471d9d3f35f>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m train(model=model,\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-94-2b0b086fa914>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, optimizer, criterion, scheduler, callback, callback_freq, additional_info)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Tokenize and pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mtokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2860\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   2946\u001b[0m                 )\n\u001b[1;32m   2947\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2948\u001b[0;31m             return self.batch_encode_plus(\n\u001b[0m\u001b[1;32m   2949\u001b[0m                 \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m                 \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mbatch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3148\u001b[0m         )\n\u001b[1;32m   3149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3150\u001b[0;31m         return self._batch_encode_plus(\n\u001b[0m\u001b[1;32m   3151\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3152\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msanitized_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eventual_warn_about_too_long_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitized_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msanitized_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     def _encode_plus(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m                     \u001b[0;31m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mas_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtensor_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTensorType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJAX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":95},{"cell_type":"code","source":"stat_file.to_csv('bpe_lstm.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:32:33.641053Z","iopub.execute_input":"2025-01-29T12:32:33.641331Z","iopub.status.idle":"2025-01-29T12:32:34.649508Z","shell.execute_reply.started":"2025-01-29T12:32:33.641311Z","shell.execute_reply":"2025-01-29T12:32:34.648631Z"}},"outputs":[],"execution_count":96},{"cell_type":"code","source":"def get_parameter_ratios(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    ratio = trainable_params / total_params\n    return trainable_params, total_params, ratio\n\n# Usage\ntrainable_params, total_params, ratio = get_parameter_ratios(classification_bert)\nprint(f\"Trainable Parameters: {trainable_params}\")\nprint(f\"Total Parameters: {total_params}\")\nprint(f\"Ratio: {ratio:.2%}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-01-29T09:54:32.277836Z","iopub.status.idle":"2025-01-29T09:54:32.278126Z","shell.execute_reply":"2025-01-29T09:54:32.278013Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.array(epoch_loss).mean(axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T08:06:27.533875Z","iopub.execute_input":"2025-01-29T08:06:27.534298Z","iopub.status.idle":"2025-01-29T08:06:27.568065Z","shell.execute_reply.started":"2025-01-29T08:06:27.534268Z","shell.execute_reply":"2025-01-29T08:06:27.566590Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-90-fe17ec87935f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of empty slice.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"],"ename":"AxisError","evalue":"axis 1 is out of bounds for array of dimension 1","output_type":"error"}],"execution_count":90},{"cell_type":"code","source":"acc_test_epoch = [a.cpu() for a in epoch_acc_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T06:59:59.332698Z","iopub.execute_input":"2025-01-12T06:59:59.332983Z","iopub.status.idle":"2025-01-12T06:59:59.337586Z","shell.execute_reply.started":"2025-01-12T06:59:59.332963Z","shell.execute_reply":"2025-01-12T06:59:59.336686Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"acc_train_epoch = []\nfor a in epoch_acc_train:\n    acc_train_epoch.append([b.cpu() for b in a ])\nacc_train_epoch = np.array(acc_train_epoch).mean(axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:00.668584Z","iopub.execute_input":"2025-01-12T07:00:00.668898Z","iopub.status.idle":"2025-01-12T07:00:00.687906Z","shell.execute_reply.started":"2025-01-12T07:00:00.668870Z","shell.execute_reply":"2025-01-12T07:00:00.686963Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"acc_train_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:02.054842Z","iopub.execute_input":"2025-01-12T07:00:02.055125Z","iopub.status.idle":"2025-01-12T07:00:02.060173Z","shell.execute_reply.started":"2025-01-12T07:00:02.055103Z","shell.execute_reply":"2025-01-12T07:00:02.059538Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"array([0.24724264, 0.6351103 , 0.77297795, 0.8327206 , 0.85294116,\n       0.88143384, 0.9117647 , 0.9108456 , 0.9338235 , 0.92922795,\n       0.92830884, 0.9319853 , 0.9393382 , 0.9237132 , 0.9503676 ,\n       0.9476103 , 0.94669116, 0.9420956 ], dtype=float32)"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1)\nax.plot(np.arange(len(acc_test_epoch)), acc_test_epoch, label='test')\nax.plot(np.arange(len(acc_train_epoch)), acc_train_epoch, label='train')\nplt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:03.534984Z","iopub.execute_input":"2025-01-12T07:00:03.535316Z","iopub.status.idle":"2025-01-12T07:00:03.740441Z","shell.execute_reply.started":"2025-01-12T07:00:03.535286Z","shell.execute_reply":"2025-01-12T07:00:03.739564Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7bdd8e39b580>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(np.arange(len(LRs)), LRs, label='test')\nplt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:15.967599Z","iopub.execute_input":"2025-01-12T07:00:15.967930Z","iopub.status.idle":"2025-01-12T07:00:16.213408Z","shell.execute_reply.started":"2025-01-12T07:00:15.967900Z","shell.execute_reply":"2025-01-12T07:00:16.212592Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7bdd8e70b9a0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkwAAAGdCAYAAADg7izUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKZUlEQVR4nO3df1hT590/8HcCJAE0iYAmYCnSFX/UUrVYsthurDOPWFkna5+pXKxSRsXtq5uOdlq3KmvXq7TaPnU6V2y36p7V+utpq8/UWilqXZVGBVt/0FLtw6y1BguUBJCfyf39A3M0GggBNJC8X9eVi+aczzm5czyQd+9z5z4yIYQAEREREXVK7usGEBEREfV3DExEREREHjAwEREREXnAwERERETkAQMTERERkQcMTEREREQeMDARERERecDARERERORBsK8bMNA4HA58/fXXGDx4MGQyma+bQ0RERN0ghEB9fT1iYmIgl3vfX8TA5KWvv/4asbGxvm4GERER9cC5c+dwyy23eL0dA5OXBg8eDKDjgKvVah+3hoiIiLrDZrMhNjZW+hz3FgOTl5yX4dRqNQMTERHRANPT4TQc9E1ERETkAQMTERERkQcMTEREREQecAwTERFRPyaEQHt7O+x2u6+b0q8FBQUhODj4hk35w8BERETUT7W2tuLChQu4dOmSr5syIISFhSE6OhoKhaLP983ARERE1A85HA5UVlYiKCgIMTExUCgUnDC5E0IItLa24ptvvkFlZSUSEhJ6NDllVxiYiIiI+qHW1lY4HA7ExsYiLCzM183p90JDQxESEoKzZ8+itbUVKpWqT/fPQd9ERET9WF/3lPizG3ms+K9ARERE5EGPAtOaNWswYsQIqFQqGAwGHD58uMv6rVu3YvTo0VCpVEhMTMSuXbtc1gshsGzZMkRHRyM0NBQmkwmnT592qamtrUVmZibUajW0Wi1ycnLQ0NAgra+oqMD9998PnU4HlUqF2267DU899RTa2tqkmvXr10Mmk7k8+rrLjoiIiPyP14Fp8+bNyMvLQ35+PsrKyjBu3Dikpqbi4sWLbusPHTqEjIwM5OTk4NixY0hPT0d6ejpOnjwp1SxfvhyrVq1CYWEhzGYzwsPDkZqaiubmZqkmMzMTp06dQlFREXbs2IEDBw4gNzdXWh8SEoLZs2djz549qKiowMqVK/Haa68hPz/fpT1qtRoXLlyQHmfPnvX2EBAREVGgEV5KTk4W8+bNk57b7XYRExMjCgoK3NbPmDFDpKWluSwzGAxi7ty5QgghHA6H0Ov1YsWKFdL6uro6oVQqxcaNG4UQQpSXlwsA4siRI1LNu+++K2QymTh//nynbf3Nb34j7rvvPun5unXrhEaj6f6bdcNqtQoAwmq19mo/REREXWlqahLl5eWiqanJ103xWkpKiliwYEGf7S8rK0tMnz7dY11Xx6y3n99efUuutbUVpaWlWLJkibRMLpfDZDKhpKTE7TYlJSXIy8tzWZaamopt27YBACorK2GxWGAymaT1Go0GBoMBJSUlmDVrFkpKSqDVajFx4kSpxmQyQS6Xw2w24yc/+cl1r3vmzBns3r0bDz30kMvyhoYGxMXFweFw4O6778Zzzz2HsWPHdvqeW1pa0NLSIj232Wyd1vbG3z6sxFffcp6NnpJBhql36pEcH+HrphARkR/yKjBVV1fDbrdDp9O5LNfpdPjss8/cbmOxWNzWWywWab1zWVc1w4YNc214cDAiIiKkGqdJkyahrKwMLS0tyM3NxTPPPCOtGzVqFF5//XXcddddsFqtePHFFzFp0iScOnUKt9xyi9v2FxQU4Omnn3a7ri/tPP41yr6su+Gv48+KP6vCB7+939fNICK6YYQQaGq7+TN+h4YEdXsOqEcffRQffPABPvjgA/zpT38C0NE50tDQgN/+9rf417/+hfDwcEyZMgUvv/wyoqKiAAD/8z//g6effhpnzpxBWFgYJkyYgO3bt2PFihX4+9//DgBSG/bt24cf/OAHff9Gu+B38zBt3rwZ9fX1+OSTT/Db3/4WL774IhYtWgQAMBqNMBqNUu2kSZMwZswYrF27Fn/84x/d7m/JkiUuPWQ2mw2xsbF93u6Hk26B8TuRfb7fQNDYYsf6Q//GhbpmCCE4sRsR+a2mNjvuWPbeTX/d8mdSEaboXmT405/+hM8//xx33nmn1GkREhKC5ORkPPbYY3j55ZfR1NSExYsXY8aMGdi7dy8uXLiAjIwMLF++HD/5yU9QX1+Pf/3rXxBC4IknnsCnn34Km82GdevWAQAiIm7+1QSvAlNUVBSCgoJQVVXlsryqqgp6vd7tNnq9vst658+qqipER0e71IwfP16quXZQeXt7O2pra697XWeYueOOO2C325Gbm4vHH38cQUFB17UtJCQEEyZMwJkzZzp9z0qlEkqlstP1fSXTEHfDX8NfNbd1BKZWuwO25nZoQkN83SQiooCl0WigUCgQFhYmfUY/++yzmDBhAp577jmp7vXXX0dsbCw+//xzNDQ0oL29HQ899BDi4jo+DxMTE6Xa0NBQtLS0dJo1bgavApNCoUBSUhKKi4uRnp4OoGPq9uLiYsyfP9/tNkajEcXFxVi4cKG0rKioSOrpiY+Ph16vR3FxsRSQbDYbzGYzfvnLX0r7qKurQ2lpKZKSkgAAe/fuhcPhgMFg6LS9DocDbW1tcDgcbgOT3W7HiRMnMG3aNG8OA/UzqpAgDFYGo76lHdUNLQxMROS3QkOCUP5Mqk9etzc++eQT7Nu3D4MGDbpu3RdffIEpU6Zg8uTJSExMRGpqKqZMmYL//M//xJAhQ3r1un3J60tyeXl5yMrKwsSJE5GcnIyVK1eisbER2dnZAIDZs2dj+PDhKCgoAAAsWLAAKSkpeOmll5CWloZNmzbh6NGjePXVVwF0XI9cuHAhnn32WSQkJCA+Ph5Lly5FTEyMFMrGjBmDqVOnYs6cOSgsLERbWxvmz5+PWbNmISYmBgCwYcMGhISEIDExEUqlEkePHsWSJUswc+ZMhIR0fIA+88wz+O53v4vbb78ddXV1WLFiBc6ePYvHHnus1weSfCtykAL1Le2oaWjFd4b6ujVERDeGTCbr9qWx/qShoQEPPvggXnjhhevWRUdHIygoCEVFRTh06BD27NmD1atX4/e//z3MZjPi4+N90OLreX3UZ86ciW+++QbLli2DxWLB+PHjsXv3bmnQ9pdffukyNfmkSZPw5ptv4qmnnsLvfvc7JCQkYNu2bbjzzjulmkWLFqGxsRG5ubmoq6vDfffdh927d7tMKrlhwwbMnz8fkydPhlwux8MPP4xVq1ZdeSPBwXjhhRfw+eefQwiBuLg4zJ8/H7/5zW+kmm+//RZz5syBxWLBkCFDkJSUhEOHDuGOO+7w9jBQPxM1SIl/11xCTUOL52IiIrqhFAoF7PYrg9PvvvtuvPXWWxgxYgSCg91HD5lMhnvvvRf33nsvli1bhri4OLzzzjvIy8u7bn++IBNCCJ+2YICx2WzQaDSwWq1Qq9W+bg5dNvcfR/HeqSr8cfpYPGIc4evmEBH1WnNzMyorKxEfHz/g7kqRm5uLjz/+GFu2bMGgQYPQ2tqK8ePHIyUlBYsWLUJERATOnDmDTZs24a9//SuOHj2K4uJiTJkyBcOGDYPZbMbPfvYzbNu2DQ888ACee+45rF27Fnv27EFkZCQ0Go109ehqXR2z3n5+815y5BciB3UMzK9uaPVxS4iI6IknnkBQUBDuuOMODB06FK2trTh48CDsdjumTJmCxMRELFy4EFqtFnK5HGq1GgcOHMC0adMwcuRIPPXUU3jppZfwwAMPAADmzJmDUaNGYeLEiRg6dCgOHjx409/TwLsQSuRGlBSYeEmOiMjXRo4c6XZC67fffttt/ZgxY7B79+5O9zd06FDs2bOnz9rXE+xhIr8QNUgBAKhhDxMREd0ADEzkF9jDRERENxIDE/mFyPDLPUyN7GEiIqK+x8BEfiFqMHuYiIjoxmFgIr8QFd4RmOqb29HsgxtTEhHdKJz9p/tu5LFiYCK/oA4NRkhQx013a3lZjoj8gHOeoUuXLvm4JQOH81i5m6OptzitAPkFmUyGyHAlLLZmVDe0IEYb6usmERH1SlBQELRarXTz+bCwMMhkMh+3qn8SQuDSpUu4ePEitFqt2/vH9hYDE/mNyEEKWGzNnFqAiPyGXq8HACk0Ude0Wq10zPoaAxP5DefUAt9w4DcR+QmZTIbo6GgMGzYMbW1tvm5OvxYSEnJDepacGJjIb0Ry8koi8lNBQUE3NAyQZxz0TX5j6OUephr2MBERUR9jYCK/4exh4lxMRETU1xiYyG9EXp6LibN9ExFRX2NgIr/hnO37m3r2MBERUd9iYCK/wfvJERHRjcLARH5j6OUeptrGVjgcvJUAERH1HQYm8hsRl3uY7A6BuibOV0JERH2HgYn8RkiQHNqwjvsHcWoBIiLqSwxM5Fec45g42zcREfUlBibyK1HS5JUc+E1ERH2HgYn8ijMwcfJKIiLqSwxM5Fd4PzkiIroRGJjIr7CHiYiIbgQGJvIrV+4nxx4mIiLqOwxM5FekQd+N7GEiIqK+w8BEfiVK6mFiYCIior7DwER+hdMKEBHRjcDARH4l8nJgutRqx6XWdh+3hoiI/AUDE/mVcEUQlMEdpzV7mYiIqK8wMJFfkclk0mU53h6FiIj6CgMT+Z0oTl5JRER9jIGJ/M6Vgd/sYSIior7BwER+J5JTCxARUR9jYCK/c+X2KLwkR0REfYOBifxOJO8nR0REfaxHgWnNmjUYMWIEVCoVDAYDDh8+3GX91q1bMXr0aKhUKiQmJmLXrl0u64UQWLZsGaKjoxEaGgqTyYTTp0+71NTW1iIzMxNqtRparRY5OTloaGiQ1ldUVOD++++HTqeDSqXCbbfdhqeeegptbW1etYUGPg76JiKivuZ1YNq8eTPy8vKQn5+PsrIyjBs3Dqmpqbh48aLb+kOHDiEjIwM5OTk4duwY0tPTkZ6ejpMnT0o1y5cvx6pVq1BYWAiz2Yzw8HCkpqaiublZqsnMzMSpU6dQVFSEHTt24MCBA8jNzZXWh4SEYPbs2dizZw8qKiqwcuVKvPbaa8jPz/eqLTTwRbGHiYiI+prwUnJyspg3b5703G63i5iYGFFQUOC2fsaMGSItLc1lmcFgEHPnzhVCCOFwOIRerxcrVqyQ1tfV1QmlUik2btwohBCivLxcABBHjhyRat59910hk8nE+fPnO23rb37zG3Hfffd1uy3dYbVaBQBhtVq7vQ3dXJ9esIq4xTvEhGf2+LopRETUT/T289urHqbW1laUlpbCZDJJy+RyOUwmE0pKStxuU1JS4lIPAKmpqVJ9ZWUlLBaLS41Go4HBYJBqSkpKoNVqMXHiRKnGZDJBLpfDbDa7fd0zZ85g9+7dSElJ6XZbyD84e5i+vdSKdrvDx60hIiJ/4FVgqq6uht1uh06nc1mu0+lgsVjcbmOxWLqsd/70VDNs2DCX9cHBwYiIiLjudSdNmgSVSoWEhAR873vfwzPPPNPttrjT0tICm83m8qD+bUiYAnIZIARQe4njmIiIqPf87ltymzdvRllZGd58803s3LkTL774Yq/2V1BQAI1GIz1iY2P7qKV0owTJZYgI58BvIiLqO14FpqioKAQFBaGqqspleVVVFfR6vdtt9Hp9l/XOn55qrh1U3t7ejtra2uteNzY2FnfccQcyMjLw/PPP4w9/+APsdnu32uLOkiVLYLVapce5c+c6raX+IzKcA7+JiKjveBWYFAoFkpKSUFxcLC1zOBwoLi6G0Wh0u43RaHSpB4CioiKpPj4+Hnq93qXGZrPBbDZLNUajEXV1dSgtLZVq9u7dC4fDAYPB0Gl7HQ4H2tra4HA4utUWd5RKJdRqtcuD+r9ITi1ARER9KNjbDfLy8pCVlYWJEyciOTkZK1euRGNjI7KzswEAs2fPxvDhw1FQUAAAWLBgAVJSUvDSSy8hLS0NmzZtwtGjR/Hqq68C6Li7/MKFC/Hss88iISEB8fHxWLp0KWJiYpCeng4AGDNmDKZOnYo5c+agsLAQbW1tmD9/PmbNmoWYmBgAwIYNGxASEoLExEQolUocPXoUS5YswcyZMxESEtKttpD/4NQCRETUp3ry1brVq1eLW2+9VSgUCpGcnCw++ugjaV1KSorIyspyqd+yZYsYOXKkUCgUYuzYsWLnzp0u6x0Oh1i6dKnQ6XRCqVSKyZMni4qKCpeampoakZGRIQYNGiTUarXIzs4W9fX10vpNmzaJu+++WwwaNEiEh4eLO+64Qzz33HOiqanJq7Z4wmkFBoY//O9JEbd4hyjY9amvm0JERP1Abz+/ZUII4evQNpDYbDZoNBpYrVZenuvH1uw7gxXvVeCnSbdgxU/H+bo5RETkY739/Pa7b8kRAVduj8JLckRE1BcYmMgvOccw1TRy0DcREfUeAxP5pUjnoO969jAREVHvMTCRX4q8PHFldWMrOEyPiIh6i4GJ/JLzklxruwP1Le0+bg0REQ10DEzkl0IVQQhXBAHg5JVERNR7DEzkt6IGXx74zW/KERFRLzEwkd+SxjExMBERUS8xMJHfunJ7FF6SIyKi3mFgIr8VyfvJERFRH2FgIr819PJs3xz0TUREvcXARH6LPUxERNRXGJjIb0Wyh4mIiPoIAxP5LWnQdyN7mIiIqHcYmMhvRV3uYeL95IiIqLcYmMhvOXuYbM3taG13+Lg1REQ0kDEwkd9Sq0IQLJcBAGp4WY6IiHqBgYn8llwu48BvIiLqEwxM5Nciwzsuy33DqQWIiKgXGJjIr7GHiYiI+gIDE/m1oZcHftewh4mIiHqBgYn8mrOHibN9ExFRbzAwkV+LknqYeEmOiIh6joGJ/JrzfnIc9E1ERL3BwER+LYqDvomIqA8wMJFfk+4nxx4mIiLqBQYm8mvOQd+1ja1wOISPW0NERAMVAxP5NefEle0OAVtzm49bQ0REAxUDE/k1RbAcalUwAF6WIyKinmNgIr8XNdg5jokDv4mIqGcYmMjvRYVz4DcREfUOAxP5vajBnFqAiIh6h4GJ/F4ke5iIiKiXGJjI7125nxx7mIiIqGcYmMjvXbmfHHuYiIioZxiYyO9FST1MDExERNQzDEzk96QepkZekiMiop7pUWBas2YNRowYAZVKBYPBgMOHD3dZv3XrVowePRoqlQqJiYnYtWuXy3ohBJYtW4bo6GiEhobCZDLh9OnTLjW1tbXIzMyEWq2GVqtFTk4OGhoapPX79+/H9OnTER0djfDwcIwfPx4bNmxw2cf69eshk8lcHiqVqieHgAaQSOf95OrZw0RERD3jdWDavHkz8vLykJ+fj7KyMowbNw6pqam4ePGi2/pDhw4hIyMDOTk5OHbsGNLT05Geno6TJ09KNcuXL8eqVatQWFgIs9mM8PBwpKamorm5WarJzMzEqVOnUFRUhB07duDAgQPIzc11eZ277roLb731Fo4fP47s7GzMnj0bO3bscGmPWq3GhQsXpMfZs2e9PQQ0wDgvyTW22tHUavdxa4iIaEASXkpOThbz5s2TntvtdhETEyMKCgrc1s+YMUOkpaW5LDMYDGLu3LlCCCEcDofQ6/VixYoV0vq6ujqhVCrFxo0bhRBClJeXCwDiyJEjUs27774rZDKZOH/+fKdtnTZtmsjOzpaer1u3Tmg0mu6/WTesVqsAIKxWa6/2QzePw+EQCb/fJeIW7xBf1jT6ujlEROQDvf389qqHqbW1FaWlpTCZTNIyuVwOk8mEkpISt9uUlJS41ANAamqqVF9ZWQmLxeJSo9FoYDAYpJqSkhJotVpMnDhRqjGZTJDL5TCbzZ2212q1IiIiwmVZQ0MD4uLiEBsbi+nTp+PUqVPdfPc0UMlkMkSFX568kuOYiIioB7wKTNXV1bDb7dDpdC7LdTodLBaL220sFkuX9c6fnmqGDRvmsj44OBgRERGdvu6WLVtw5MgRZGdnS8tGjRqF119/Hdu3b8cbb7wBh8OBSZMm4auvvur0Pbe0tMBms7k8aOBx3k+OUwsQEVFP+OW35Pbt24fs7Gy89tprGDt2rLTcaDRi9uzZGD9+PFJSUvD2229j6NChWLt2baf7KigogEajkR6xsbE34y1QH4sM59QCRETUc14FpqioKAQFBaGqqspleVVVFfR6vdtt9Hp9l/XOn55qrh1U3t7ejtra2ute94MPPsCDDz6Il19+GbNnz+7y/YSEhGDChAk4c+ZMpzVLliyB1WqVHufOnetyn9Q/OacW4GzfRETUE14FJoVCgaSkJBQXF0vLHA4HiouLYTQa3W5jNBpd6gGgqKhIqo+Pj4der3epsdlsMJvNUo3RaERdXR1KS0ulmr1798LhcMBgMEjL9u/fj7S0NLzwwgsu36DrjN1ux4kTJxAdHd1pjVKphFqtdnnQwCNNLcAeJiIi6oFgbzfIy8tDVlYWJk6ciOTkZKxcuRKNjY3SWKHZs2dj+PDhKCgoAAAsWLAAKSkpeOmll5CWloZNmzbh6NGjePXVVwF0DMhduHAhnn32WSQkJCA+Ph5Lly5FTEwM0tPTAQBjxozB1KlTMWfOHBQWFqKtrQ3z58/HrFmzEBMTA6DjMtyPfvQjLFiwAA8//LA0tkmhUEgDv5955hl897vfxe233466ujqsWLECZ8+exWOPPda7o0j9nnNqgRr2MBERUU/05Kt1q1evFrfeeqtQKBQiOTlZfPTRR9K6lJQUkZWV5VK/ZcsWMXLkSKFQKMTYsWPFzp07XdY7HA6xdOlSodPphFKpFJMnTxYVFRUuNTU1NSIjI0MMGjRIqNVqkZ2dLerr66X1WVlZAsB1j5SUFKlm4cKFUrt1Op2YNm2aKCsr8+q9c1qBgemdsq9E3OIdIuPVEl83hYiIfKC3n98yIYTwYV4bcGw2GzQaDaxWKy/PDSAfnq7Gz/5mxijdYLz3m+/7ujlERHST9fbz2y+/JUd0rUjnJblGjmEiIiLvMTBRQHAGptrGVtgd7FQlIiLvMDBRQIgIU0AmAxwC+PYSB34TEZF3GJgoIAQHyTEkjJNXEhFRzzAwUcDg1AJERNRTDEwUMCLDOXklERH1DAMTBQznDXh5exQiIvIWAxMFDOcNeGvYw0RERF5iYKKA4RzDxEtyRETkLQYmChhRl2/Ay0HfRETkLQYmChiRgzjom4iIeoaBiQLGlUty7GEiIiLvMDBRwIi6qoeJ95wmIiJvMDBRwHDeT66l3YHGVruPW0NERAMJAxMFjDBFMMIUQQA4tQAREXmHgYkCSiSnFiAioh5gYKKAcmUcEwd+ExFR9zEwUUDh/eSIiKgnGJgooAwd7Lw9CnuYiIio+xiYKKCwh4mIiHqCgYkCinPySvYwERGRNxiYKKDw9ihERNQTDEwUUDitABER9QQDEwWUoZd7mGoaeUmOiIi6j4GJAorzklzdpTa02R0+bg0REQ0UDEwUULShIQiSywAAtexlIiKibmJgooAil8sQEd4xjumbeo5jIiKi7mFgooATxXFMRETkJQYmCjhX5mJiDxMREXUPAxMFnCjOxURERF5iYKKAExnO2b6JiMg7DEwUcJxTC3zDHiYiIuomBiYKOLyfHBEReYuBiQIOxzAREZG3GJgo4EjTCrCHiYiIuomBiQKO8wa8NY0tEEL4uDVERDQQMDBRwHEGpja7gK2p3cetISKigaBHgWnNmjUYMWIEVCoVDAYDDh8+3GX91q1bMXr0aKhUKiQmJmLXrl0u64UQWLZsGaKjoxEaGgqTyYTTp0+71NTW1iIzMxNqtRparRY5OTloaGiQ1u/fvx/Tp09HdHQ0wsPDMX78eGzYsMHrtpD/UwYHYbAqGABQ3chxTERE5JnXgWnz5s3Iy8tDfn4+ysrKMG7cOKSmpuLixYtu6w8dOoSMjAzk5OTg2LFjSE9PR3p6Ok6ePCnVLF++HKtWrUJhYSHMZjPCw8ORmpqK5uZmqSYzMxOnTp1CUVERduzYgQMHDiA3N9flde666y689dZbOH78OLKzszF79mzs2LHDq7ZQYJAGfvN+ckRE1B3CS8nJyWLevHnSc7vdLmJiYkRBQYHb+hkzZoi0tDSXZQaDQcydO1cIIYTD4RB6vV6sWLFCWl9XVyeUSqXYuHGjEEKI8vJyAUAcOXJEqnn33XeFTCYT58+f77St06ZNE9nZ2d1uS3dYrVYBQFit1m5vQ/3Pf75yUMQt3iF2Hv/a100hIqKboLef3171MLW2tqK0tBQmk0laJpfLYTKZUFJS4nabkpISl3oASE1NleorKythsVhcajQaDQwGg1RTUlICrVaLiRMnSjUmkwlyuRxms7nT9lqtVkRERHS7LRQ4IsM5tQAREXVfsDfF1dXVsNvt0Ol0Lst1Oh0+++wzt9tYLBa39RaLRVrvXNZVzbBhw1wbHhyMiIgIqeZaW7ZswZEjR7B27dput8WdlpYWtLRc+VC12Wyd1tLAETW4Y+B3NacWICKibvDLb8nt27cP2dnZeO211zB27Nhe7augoAAajUZ6xMbG9lEryZecPUw17GEiIqJu8CowRUVFISgoCFVVVS7Lq6qqoNfr3W6j1+u7rHf+9FRz7aDy9vZ21NbWXve6H3zwAR588EG8/PLLmD17tldtcWfJkiWwWq3S49y5c53W0sARNZiX5IiIqPu8CkwKhQJJSUkoLi6WljkcDhQXF8NoNLrdxmg0utQDQFFRkVQfHx8PvV7vUmOz2WA2m6Uao9GIuro6lJaWSjV79+6Fw+GAwWCQlu3fvx9paWl44YUXXL5B1922uKNUKqFWq10eNPBFhfN+ckRE5AVvR4lv2rRJKJVKsX79elFeXi5yc3OFVqsVFotFCCHEI488Ip588kmp/uDBgyI4OFi8+OKL4tNPPxX5+fkiJCREnDhxQqp5/vnnhVarFdu3bxfHjx8X06dPF/Hx8aKpqUmqmTp1qpgwYYIwm83iww8/FAkJCSIjI0Nav3fvXhEWFiaWLFkiLly4ID1qamq8aosn/JacfzD/X42IW7xDpCzf6+umEBHRTdDbz2+vA5MQQqxevVrceuutQqFQiOTkZPHRRx9J61JSUkRWVpZL/ZYtW8TIkSOFQqEQY8eOFTt37nRZ73A4xNKlS4VOpxNKpVJMnjxZVFRUuNTU1NSIjIwMMWjQIKFWq0V2draor6+X1mdlZQkA1z1SUlK8aosnDEz+4YuL9SJu8Q5x57Ldvm4KERHdBL39/JYJwZtpecNms0Gj0cBqtfLy3ABmbWrDuKf3AAA+++NUqEKCfNwiIiK6kXr7+e2X35Ij8kStCoYiqOP0r2nkOCYiIuoaAxMFJJlMJt2El1MLEBGRJwxMFLCk+8kxMBERkQcMTBSwnD1MnO2biIg8YWCigMX7yRERUXcxMFHAct5PjpNXEhGRJwxMFLCi2MNERETdxMBEAYs9TERE1F0MTBSwOIaJiIi6i4GJAtaVaQXYw0RERF1jYKKAFXV5WoHaxhY4HLxDEBERdY6BiQLWkPCOwOQQwLeX2MtERESdY2CigBUSJMeQsBAAvJ8cERF1jYGJAlqkcxxTPQd+ExFR5xiYKKA5xzFVs4eJiIi6wMBEAc3Zw1TDqQWIiKgLDEwU0IYO4lxMRETkGQMTBbTIcM72TUREnjEwUUCLGsweJiIi8oyBiQKas4eJs30TEVFXGJgooEVyDBMREXUDAxMFtKHSt+TYw0RERJ1jYKKAFnl5HqamNjsutbb7uDVERNRfMTBRQAtXBiM0JAgAUF3PXiYiInKPgYkCXqQ02zfHMRERkXsMTBTwong/OSIi8oCBiQKe835yNbyfHBERdYKBiQJeZDh7mIiIqGsMTBTwogazh4mIiLrGwEQBT+ph4uSVRETUCQYmCni8nxwREXnCwEQBL+ry/eQ42zcREXWGgYkCHnuYiIjIEwYmCniRl3uYvr3Uhna7w8etISKi/oiBiQKeNkwBuazjv2v5TTkiInKDgYkCXpBchgjpm3IMTEREdD0GJiJcPds3xzEREdH1ehSY1qxZgxEjRkClUsFgMODw4cNd1m/duhWjR4+GSqVCYmIidu3a5bJeCIFly5YhOjoaoaGhMJlMOH36tEtNbW0tMjMzoVarodVqkZOTg4aGBml9c3MzHn30USQmJiI4OBjp6enXtWP//v2QyWTXPSwWS08OA/kR6X5yHPhNRERueB2YNm/ejLy8POTn56OsrAzjxo1DamoqLl686Lb+0KFDyMjIQE5ODo4dO4b09HSkp6fj5MmTUs3y5cuxatUqFBYWwmw2Izw8HKmpqWhubpZqMjMzcerUKRQVFWHHjh04cOAAcnNzpfV2ux2hoaH49a9/DZPJ1OV7qKiowIULF6THsGHDvD0M5GciB3FqASIi6oLwUnJyspg3b5703G63i5iYGFFQUOC2fsaMGSItLc1lmcFgEHPnzhVCCOFwOIRerxcrVqyQ1tfV1QmlUik2btwohBCivLxcABBHjhyRat59910hk8nE+fPnr3vNrKwsMX369OuW79u3TwAQ3377bbff77WsVqsAIKxWa4/3Qf3PM/88JeIW7xDP7Sr3dVOIiOgG6O3nt1c9TK2trSgtLXXpwZHL5TCZTCgpKXG7TUlJyXU9PqmpqVJ9ZWUlLBaLS41Go4HBYJBqSkpKoNVqMXHiRKnGZDJBLpfDbDZ78xYAAOPHj0d0dDT+4z/+AwcPHvR6e/I/7GEiIqKueBWYqqurYbfbodPpXJbrdLpOxwFZLJYu650/PdVce9ksODgYERERXo0/io6ORmFhId566y289dZbiI2NxQ9+8AOUlZV1uk1LSwtsNpvLg/xPFO8nR0REXQj2dQNuplGjRmHUqFHS80mTJuGLL77Ayy+/jH/84x9utykoKMDTTz99s5pIPhI1mD1MRETUOa96mKKiohAUFISqqiqX5VVVVdDr9W630ev1XdY7f3qquXZQeXt7O2prazt93e5KTk7GmTNnOl2/ZMkSWK1W6XHu3LlevR71T5GXe5hq2MNERERueBWYFAoFkpKSUFxcLC1zOBwoLi6G0Wh0u43RaHSpB4CioiKpPj4+Hnq93qXGZrPBbDZLNUajEXV1dSgtLZVq9u7dC4fDAYPB4M1buM7HH3+M6OjoTtcrlUqo1WqXB/mfK/eTa4UQwsetISKi/sbrS3J5eXnIysrCxIkTkZycjJUrV6KxsRHZ2dkAgNmzZ2P48OEoKCgAACxYsAApKSl46aWXkJaWhk2bNuHo0aN49dVXAQAymQwLFy7Es88+i4SEBMTHx2Pp0qWIiYmR5lIaM2YMpk6dijlz5qCwsBBtbW2YP38+Zs2ahZiYGKlt5eXlaG1tRW1tLerr6/Hxxx8D6BjkDQArV65EfHw8xo4di+bmZvz1r3/F3r17sWfPnp4eP/ITzvvJtdodqG9ph1oV4uMWERFRf+J1YJo5cya++eYbLFu2DBaLBePHj8fu3bulQdtffvkl5PIrHVeTJk3Cm2++iaeeegq/+93vkJCQgG3btuHOO++UahYtWoTGxkbk5uairq4O9913H3bv3g2VSiXVbNiwAfPnz8fkyZMhl8vx8MMPY9WqVS5tmzZtGs6ePSs9nzBhAgBIPQatra14/PHHcf78eYSFheGuu+7C+++/j/vvv9/bw0B+RhUShMHKYNS3tKO6voWBiYiIXMgErz94xWazQaPRwGq18vKcn/nBin34d80lbP2FEfeMiPB1c4iIqA/19vOb95IjuizSeXuUeg78JiIiVwxMRJc5b8Bb3cipBYiIyBUDE9Flzh4mTi1ARETXYmAiuixqEGf7JiIi9xiYiC6L4v3kiIioEwxMRJexh4mIiDrDwER0mXPySvYwERHRtRiYiC5z3h7lG/YwERHRNRiYiC6LunwD3vrmdrS0233cGiIi6k8YmIguU4cGIyRIBgCo5VxMRER0FQYmostkMhkiw52zfTMwERHRFQxMRFeJlGb75jgmIiK6goGJ6CpRvJ8cERG5wcBEdBVnD1MNxzAREdFVGJiIrjKUPUxEROQGAxPRVdjDRERE7jAwEV1F+pYcJ68kIqKrMDARXcU523c1b49CRERXYWAiusqV+8mxh4mIiK5gYCK6ytDLPUw1ja1wOISPW0NERP0FAxPRVSIu9zDZHQLWpjYft4aIiPoLBiaiq4QEyaENCwHAgd9ERHQFAxPRNZzjmDjwm4iInBiYiK4ROcg5jok9TERE1IGBieganO2biIiuxcBEdA3O9k1ERNdiYCK6RtQgzvZNRESuGJiIruHsYeKgbyIicmJgIroGe5iIiOhaDExE14hyjmFiDxMREV3GwER0jcjwy9MKsIeJiIguY2AiukbU5fvJNbba0dRq93FriIioP2BgIrpGuCIIyuCOXw2OYyIiIoCBieg6MpmMA7+JiMgFAxORGxz4TUREV2NgInKDPUxERHQ1BiYiN3h7FCIiuhoDE5EbkexhIiKiq/QoMK1ZswYjRoyASqWCwWDA4cOHu6zfunUrRo8eDZVKhcTEROzatctlvRACy5YtQ3R0NEJDQ2EymXD69GmXmtraWmRmZkKtVkOr1SInJwcNDQ3S+ubmZjz66KNITExEcHAw0tPT3bZl//79uPvuu6FUKnH77bdj/fr1PTkE5OeuXJJjDxMREfUgMG3evBl5eXnIz89HWVkZxo0bh9TUVFy8eNFt/aFDh5CRkYGcnBwcO3YM6enpSE9Px8mTJ6Wa5cuXY9WqVSgsLITZbEZ4eDhSU1PR3Nws1WRmZuLUqVMoKirCjh07cODAAeTm5krr7XY7QkND8etf/xomk8ltWyorK5GWlob7778fH3/8MRYuXIjHHnsM7733nreHgfzclUHf7GEiIiIAwkvJycli3rx50nO73S5iYmJEQUGB2/oZM2aItLQ0l2UGg0HMnTtXCCGEw+EQer1erFixQlpfV1cnlEql2LhxoxBCiPLycgFAHDlyRKp59913hUwmE+fPn7/uNbOyssT06dOvW75o0SIxduxYl2UzZ84UqampHt71FVarVQAQVqu129vQwPPh6W9E3OId4j/+a7+vm0JERH2gt5/fXvUwtba2orS01KUHRy6Xw2QyoaSkxO02JSUl1/X4pKamSvWVlZWwWCwuNRqNBgaDQaopKSmBVqvFxIkTpRqTyQS5XA6z2dzt9ntqizstLS2w2WwuD/J/kZxWgIiIruJVYKqurobdbodOp3NZrtPpYLFY3G5jsVi6rHf+9FQzbNgwl/XBwcGIiIjo9HW9aYvNZkNTU5PbbQoKCqDRaKRHbGxst1+PBi7nGKbaS61otzt83BoiIvI1fkvOgyVLlsBqtUqPc+fO+bpJdBMMCVNALgOEAL691Obr5hARkY95FZiioqIQFBSEqqoql+VVVVXQ6/Vut9Hr9V3WO396qrl2UHl7eztqa2s7fV1v2qJWqxEaGup2G6VSCbVa7fIg/xcklyEi3DkXEwd+ExEFOq8Ck0KhQFJSEoqLi6VlDocDxcXFMBqNbrcxGo0u9QBQVFQk1cfHx0Ov17vU2Gw2mM1mqcZoNKKurg6lpaVSzd69e+FwOGAwGLrdfk9tIbpaZPjlqQXqOY6JiCjQBXu7QV5eHrKysjBx4kQkJydj5cqVaGxsRHZ2NgBg9uzZGD58OAoKCgAACxYsQEpKCl566SWkpaVh06ZNOHr0KF599VUAHTc6XbhwIZ599lkkJCQgPj4eS5cuRUxMjDSX0pgxYzB16lTMmTMHhYWFaGtrw/z58zFr1izExMRIbSsvL0draytqa2tRX1+Pjz/+GAAwfvx4AMAvfvEL/PnPf8aiRYvw85//HHv37sWWLVuwc+fOnh4/8mORgxRAFXuYiIgI3k8rIIQQq1evFrfeeqtQKBQiOTlZfPTRR9K6lJQUkZWV5VK/ZcsWMXLkSKFQKMTYsWPFzp07XdY7HA6xdOlSodPphFKpFJMnTxYVFRUuNTU1NSIjI0MMGjRIqNVqkZ2dLerr611q4uLiBIDrHlfbt2+fGD9+vFAoFOK2224T69at8+q9c1qBwPGrN8tE3OId4rUDX/i6KURE1Eu9/fyWCSGED/PagGOz2aDRaGC1Wjmeyc89/c9TWHfw3/jlD76DxVNH+7o5RETUC739/Oa35Ig6Id0epZ6X5IiIAh0DE1EnpNujNHLQNxFRoGNgIuqEs4eJ95MjIiIGJqJORDovyfH2KEREAY+BiagTkZcnrqxuaAG/G0FEFNgYmIg64bwk19LuQENLu49bQ0REvsTARNSJUEUQwhVBAIAaXpYjIgpoDExEXYga7BzHxIHfRESBjIGJqAtXxjGxh4mIKJAxMBF1QZpagPeTIyIKaAxMRF2QphaoZw8TEVEgY2Ai6sKV2b7Zw0REFMgYmIi6IN1PjoO+iYgCGgMTURciB3HQNxERMTARdYk9TEREBDAwEXVJGsPEHiYiooDGwETUBWcPk7WpDa3tDh+3hoiIfIWBiagLalUIguUyAEBtI3uZiIgCFQMTURfkchkipNm+OY6JiChQMTARecCB30RExMBE5EEkB34TEQU8BiYiD4ayh4mIKOAxMBF5IPUwcdA3EVHAYmAi8oBjmIiIiIGJyINIKTCxh4mIKFAxMBF5cGXQN3uYiIgCFQMTkQcc9E1ERAxMRB5cPa2AEMLHrSEiIl9gYCLyIDK8o4ep3SFgbWrzcWuIiMgXGJiIPFAEy6FWBQPgwG8iokDFwETUDVGDO3qZOPCbiCgwMTARdUNUOKcWICIKZAxMRN0QNdg52zd7mIiIAhEDE1E3OAd+V9czMBERBSIGJqJucE4tUM37yRERBSQGJqJukO4nxx4mIqKAxMBE1A1Rzskr2cNERBSQehSY1qxZgxEjRkClUsFgMODw4cNd1m/duhWjR4+GSqVCYmIidu3a5bJeCIFly5YhOjoaoaGhMJlMOH36tEtNbW0tMjMzoVarodVqkZOTg4aGBpea48eP43vf+x5UKhViY2OxfPlyl/Xr16+HTCZzeahUqp4cAgowzh4mTitARBSYvA5MmzdvRl5eHvLz81FWVoZx48YhNTUVFy9edFt/6NAhZGRkICcnB8eOHUN6ejrS09Nx8uRJqWb58uVYtWoVCgsLYTabER4ejtTUVDQ3N0s1mZmZOHXqFIqKirBjxw4cOHAAubm50nqbzYYpU6YgLi4OpaWlWLFiBf7whz/g1VdfdWmPWq3GhQsXpMfZs2e9PQQUgCIHcVoBIqKAJryUnJws5s2bJz232+0iJiZGFBQUuK2fMWOGSEtLc1lmMBjE3LlzhRBCOBwOodfrxYoVK6T1dXV1QqlUio0bNwohhCgvLxcAxJEjR6Sad999V8hkMnH+/HkhhBB/+ctfxJAhQ0RLS4tUs3jxYjFq1Cjp+bp164RGo/H2LbuwWq0CgLBarb3aDw0stqZWEbd4h4hbvEM0tbb7ujlEROSl3n5+e9XD1NraitLSUphMJmmZXC6HyWRCSUmJ221KSkpc6gEgNTVVqq+srITFYnGp0Wg0MBgMUk1JSQm0Wi0mTpwo1ZhMJsjlcpjNZqnm+9//PhQKhcvrVFRU4Ntvv5WWNTQ0IC4uDrGxsZg+fTpOnTrV5XtuaWmBzWZzeVDgGaQMhiK449elmpfliIgCjleBqbq6Gna7HTqdzmW5TqeDxWJxu43FYumy3vnTU82wYcNc1gcHByMiIsKlxt0+rn6NUaNG4fXXX8f27dvxxhtvwOFwYNKkSfjqq686fc8FBQXQaDTSIzY2ttNa8l8ymQxR4ZcHfvOyHBFRwAmob8kZjUbMnj0b48ePR0pKCt5++20MHToUa9eu7XSbJUuWwGq1So9z587dxBZTf+K8nxx7mIiIAo9XgSkqKgpBQUGoqqpyWV5VVQW9Xu92G71e32W986enmmsHlbe3t6O2ttalxt0+rn6Na4WEhGDChAk4c+aM+zcMQKlUQq1WuzwoMEWyh4mIKGB5FZgUCgWSkpJQXFwsLXM4HCguLobRaHS7jdFodKkHgKKiIqk+Pj4eer3epcZms8FsNks1RqMRdXV1KC0tlWr27t0Lh8MBg8Eg1Rw4cABtbW0urzNq1CgMGTLEbdvsdjtOnDiB6Ohobw4DBShp8kreT46IKPB4O0p806ZNQqlUivXr14vy8nKRm5srtFqtsFgsQgghHnnkEfHkk09K9QcPHhTBwcHixRdfFJ9++qnIz88XISEh4sSJE1LN888/L7Rardi+fbs4fvy4mD59uoiPjxdNTU1SzdSpU8WECROE2WwWH374oUhISBAZGRnS+rq6OqHT6cQjjzwiTp48KTZt2iTCwsLE2rVrpZqnn35avPfee+KLL74QpaWlYtasWUKlUolTp051+/3zW3KBq2DXpyJu8Q7x9P92/3whIqL+obef38HeBqyZM2fim2++wbJly2CxWDB+/Hjs3r1bGmD95ZdfQi6/0nE1adIkvPnmm3jqqafwu9/9DgkJCdi2bRvuvPNOqWbRokVobGxEbm4u6urqcN9992H37t0uk0pu2LAB8+fPx+TJkyGXy/Hwww9j1apV0nqNRoM9e/Zg3rx5SEpKQlRUFJYtW+YyV9O3336LOXPmwGKxYMiQIUhKSsKhQ4dwxx13eHsYKABdme2bPUxERIFGJoQQvm7EQGKz2aDRaGC1WjmeKcBsO3YeCzd/jHtvj8SGx77r6+YQEZEXevv5HVDfkiPqjchBHPRNRBSoGJiIukka9M1pBYiIAg4DE1E3OXuYahtbYXfwSjYRUSBhYCLqpogwBWQywCGAuku8LEdEFEgYmIi6KThIjiFhHb1M1RzHREQUUBiYiLwgTS3AcUxERAHF63mYiAJZZLgSQAN+veljhCuDfN0c6oJaFYLfTRsD43cifd0UIvIDDExEXki8RYOS/6tBdUMLqht83RryZM5/H8WWuUbcEcM504iodzhxpZc4cWVgszsEyr+2odXu8HVTqEsCK96rwEf/Vwu9WoV35k1CtCbU140iIh/q7ec3A5OXGJiIBgbrpTb8Z+EhnL7YgNH6wdjyCyPUqhBfN4uIfIQzfRMRuaEJC8G67HswdLASn1nq8cs3StHazp5BIuoZBiYi8lu3DAnDukfvQZgiCAfP1ODJt4+DnepE1BMMTETk1+4crsGazLsRJJfh7bLzePn9075uEhENQAxMROT37h81DM+m3wkAWFV8GpuPfOnjFhHRQMPAREQBISP5Vsy//3YAwO/eOYkPPv/Gxy0iooGEgYmIAsbjU0bioQnDYXcI/L83SnHqa6uvm0REAwQDExEFDJlMhucfvgvG2yLR2GpH9rojOF/X5OtmEdEAwMBERAFFESxH4SNJGKkbhIv1LchedxjWpjZfN4uI+jkGJiIKOJrQEKzPToZOrcTnVQ34xT84RxMRdY2BiYgCUow2FK8/eg/CFUEo+b8aLH6LczQRUecYmIgoYI2N0eAvP0tCkFyGd46dx0t7Pvd1k4ion2JgIqKAljJyKAp+kggA+PO+M9h4mHM0EdH1GJiIKODNuCcWv56cAAB4attJ7Ku46OMWEVF/w8BERATgN6YEPHz3LbA7BOZtKMPJ85yjiYiuYGAiIkLHHE0FDyXivtujcKnVjuz1R/DVt5d83Swi6icYmIiILlMEy/GXn92N0frB+Ka+BY+uOwLrJc7RREQMTERELtSqEKzLvgd6tQpnLjYg9x9H0dJu93WziMjHGJiIiK4RrQnFuux7MEgZDHNlLX679TgcDs7RRBTIGJiIiNwYE63GKz+7G8FyGf73k6/x4p4KXzeJiHyIgYmIqBPfSxiKgoc65mj6y/4vsMF81sctIiJfYWAiIurCTyfGYqGpY46mpdtOovjTKh+3iIh8gYGJiMiDBZMT8NOkW+AQwPw3j+H4V3W+bhIR3WQMTEREHshkMjz3UCK+lxCFpjY7fr7+KM7Vco4mokDCwERE1A0hQXL8JfNujIlWo7qhBY+uO4y6S62+bhYR3SQMTERE3TRYFYJ1j96DaI0KX3zTiNx/lHKOJqIAwcBEROQFvUaFddn3YLAyGIcra/EE52giCgjBvm4AEdFAM1qvRuEjSXh03WH885Ov0djSjmiNytfNIg9CQ4Kg16gQow3teGhUiBqkhFwu83XTaADoUWBas2YNVqxYAYvFgnHjxmH16tVITk7utH7r1q1YunQp/v3vfyMhIQEvvPACpk2bJq0XQiA/Px+vvfYa6urqcO+99+KVV15BQkKCVFNbW4tf/epX+Oc//wm5XI6HH34Yf/rTnzBo0CCp5vjx45g3bx6OHDmCoUOH4le/+hUWLVrkVVuIiLrj3tuj8MLDdyFvyyfY+9lFXzeHeigkSAa9RoVoTUeAir4cpGK0oR3LtCpoQkMgkzFUBTqvA9PmzZuRl5eHwsJCGAwGrFy5EqmpqaioqMCwYcOuqz906BAyMjJQUFCAH/3oR3jzzTeRnp6OsrIy3HnnnQCA5cuXY9WqVfj73/+O+Ph4LF26FKmpqSgvL4dK1fF/bZmZmbhw4QKKiorQ1taG7Oxs5Obm4s033wQA2Gw2TJkyBSaTCYWFhThx4gR+/vOfQ6vVIjc3t9ttISLqrofuvgXDBqtQevZbXzeFuqGhpQ1fW5txoa4JX9c142J9M9rsAudqm3CutqnT7UJDghCjdYaojnA1XBuKaK1KClVhCl6w8XcyIYRXF98NBgPuuece/PnPfwYAOBwOxMbG4le/+hWefPLJ6+pnzpyJxsZG7NixQ1r23e9+F+PHj0dhYSGEEIiJicHjjz+OJ554AgBgtVqh0+mwfv16zJo1C59++inuuOMOHDlyBBMnTgQA7N69G9OmTcNXX32FmJgYvPLKK/j9738Pi8UChUIBAHjyySexbds2fPbZZ91qS3fYbDZoNBpYrVao1WpvDh0REfUj7XYHqupbOgKUtRlf1zVJ/33B2oQLdc2oaezeNyG1YSFSL5Veo4IimEOEe+Pn98YjNiKsT/fZ289vryJxa2srSktLsWTJEmmZXC6HyWRCSUmJ221KSkqQl5fnsiw1NRXbtm0DAFRWVsJiscBkMknrNRoNDAYDSkpKMGvWLJSUlECr1UphCQBMJhPkcjnMZjN+8pOfoKSkBN///velsOR8nRdeeAHffvsthgwZ4rEt7rS0tKClpUV6brPZOj9AREQ0YAQHyTFc29Fb1JnmNjsuOHulpJ8dPVTOUFXf0o66S22ou9SGTy/wM6IvPDgups8DU295FZiqq6tht9uh0+lclut0OqkX51oWi8VtvcVikdY7l3VVc+3lvuDgYERERLjUxMfHX7cP57ohQ4Z4bIs7BQUFePrppztdT0RE/ksVEoT4qHDER4V3WmNrbsOFumZ8fTlAWWzNsDscN7GV/ken7n9fouBFVw+WLFni0itls9kQGxvrwxYREVF/olaFQK0PwSj9YF83hW4gry6yRkVFISgoCFVVrjefrKqqgl6vd7uNXq/vst7501PNxYuu30Jpb29HbW2tS427fVz9Gp7a4o5SqYRarXZ5EBERUWDxKjApFAokJSWhuLhYWuZwOFBcXAyj0eh2G6PR6FIPAEVFRVJ9fHw89Hq9S43NZoPZbJZqjEYj6urqUFpaKtXs3bsXDocDBoNBqjlw4ADa2tpcXmfUqFEYMmRIt9pCRERE5Jbw0qZNm4RSqRTr168X5eXlIjc3V2i1WmGxWIQQQjzyyCPiySeflOoPHjwogoODxYsvvig+/fRTkZ+fL0JCQsSJEyekmueff15otVqxfft2cfz4cTF9+nQRHx8vmpqapJqpU6eKCRMmCLPZLD788EORkJAgMjIypPV1dXVCp9OJRx55RJw8eVJs2rRJhIWFibVr13rVFk+sVqsAIKxWq7eHjoiIiHykt5/fXgcmIYRYvXq1uPXWW4VCoRDJycnio48+ktalpKSIrKwsl/otW7aIkSNHCoVCIcaOHSt27tzpst7hcIilS5cKnU4nlEqlmDx5sqioqHCpqampERkZGWLQoEFCrVaL7OxsUV9f71LzySefiPvuu08olUoxfPhw8fzzz1/Xdk9t8YSBiYiIaODp7ee31/MwBTrOw0RERDTw9PbzmzNrEREREXnAwERERETkAQMTERERkQcMTEREREQeMDARERERecDAREREROQBAxMRERGRBwxMRERERB4E+7oBA41znk+bzebjlhAREVF3OT+3ezpfNwOTl+rr6wEAsbGxPm4JEREReau+vh4ajcbr7XhrFC85HA58/fXXGDx4MGQyWZ/t12azITY2FufOnQv4W67wWHTgcejA43AFj0UHHocOPA4dunschBCor69HTEwM5HLvRySxh8lLcrkct9xyyw3bv1qtDugT/2o8Fh14HDrwOFzBY9GBx6EDj0OH7hyHnvQsOXHQNxEREZEHDExEREREHjAw9RNKpRL5+flQKpW+borP8Vh04HHowONwBY9FBx6HDjwOHW7WceCgbyIiIiIP2MNERERE5AEDExEREZEHDExEREREHjAwEREREXnAwHQTrVmzBiNGjIBKpYLBYMDhw4e7rN+6dStGjx4NlUqFxMRE7Nq16ya19MYpKCjAPffcg8GDB2PYsGFIT09HRUVFl9usX78eMpnM5aFSqW5Si2+MP/zhD9e9p9GjR3e5jT+eDyNGjLjuOMhkMsybN89tvT+dCwcOHMCDDz6ImJgYyGQybNu2zWW9EALLli1DdHQ0QkNDYTKZcPr0aY/79fbvjK91dRza2tqwePFiJCYmIjw8HDExMZg9eza+/vrrLvfZk98vX/N0Pjz66KPXvaepU6d63O9AOx8Az8fC3d8MmUyGFStWdLrPvjgnGJhuks2bNyMvLw/5+fkoKyvDuHHjkJqaiosXL7qtP3ToEDIyMpCTk4Njx44hPT0d6enpOHny5E1ued/64IMPMG/ePHz00UcoKipCW1sbpkyZgsbGxi63U6vVuHDhgvQ4e/bsTWrxjTN27FiX9/Thhx92Wuuv58ORI0dcjkFRUREA4Kc//Wmn2/jLudDY2Ihx48ZhzZo1btcvX74cq1atQmFhIcxmM8LDw5Gamorm5uZO9+nt35n+oKvjcOnSJZSVlWHp0qUoKyvD22+/jYqKCvz4xz/2uF9vfr/6A0/nAwBMnTrV5T1t3Lixy30OxPMB8Hwsrj4GFy5cwOuvvw6ZTIaHH364y/32+pwQdFMkJyeLefPmSc/tdruIiYkRBQUFbutnzJgh0tLSXJYZDAYxd+7cG9rOm+3ixYsCgPjggw86rVm3bp3QaDQ3r1E3QX5+vhg3bly36wPlfFiwYIH4zne+IxwOh9v1/nguCCEEAPHOO+9Izx0Oh9Dr9WLFihXSsrq6OqFUKsXGjRs73Y+3f2f6m2uPgzuHDx8WAMTZs2c7rfH296u/cXccsrKyxPTp073az0A/H4To3jkxffp08cMf/rDLmr44J9jDdBO0traitLQUJpNJWiaXy2EymVBSUuJ2m5KSEpd6AEhNTe20fqCyWq0AgIiIiC7rGhoaEBcXh9jYWEyfPh2nTp26Gc27oU6fPo2YmBjcdtttyMzMxJdfftlpbSCcD62trXjjjTfw85//vMsbW/vjuXCtyspKWCwWl39zjUYDg8HQ6b95T/7ODERWqxUymQxarbbLOm9+vwaK/fv3Y9iwYRg1ahR++ctfoqamptPaQDkfqqqqsHPnTuTk5His7e05wcB0E1RXV8Nut0On07ks1+l0sFgsbrexWCxe1Q9EDocDCxcuxL333os777yz07pRo0bh9ddfx/bt2/HGG2/A4XBg0qRJ+Oqrr25ia/uWwWDA+vXrsXv3brzyyiuorKzE9773PdTX17utD4TzYdu2bairq8Ojjz7aaY0/ngvuOP9dvfk378nfmYGmubkZixcvRkZGRpc3WfX292sgmDp1Kv77v/8bxcXFeOGFF/DBBx/ggQcegN1ud1sfCOcDAPz973/H4MGD8dBDD3VZ1xfnRHBvG0vUU/PmzcPJkyc9Xkc2Go0wGo3S80mTJmHMmDFYu3Yt/vjHP97oZt4QDzzwgPTfd911FwwGA+Li4rBly5Zu/Z+SP/rb3/6GBx54ADExMZ3W+OO5QN3T1taGGTNmQAiBV155pctaf/z9mjVrlvTfiYmJuOuuu/Cd73wH+/fvx+TJk33YMt96/fXXkZmZ6fHLH31xTrCH6SaIiopCUFAQqqqqXJZXVVVBr9e73Uav13tVP9DMnz8fO3bswL59+3DLLbd4tW1ISAgmTJiAM2fO3KDW3XxarRYjR47s9D35+/lw9uxZvP/++3jssce82s4fzwUA0r+rN//mPfk7M1A4w9LZs2dRVFTUZe+SO55+vwai2267DVFRUZ2+J38+H5z+9a9/oaKiwuu/G0DPzgkGpptAoVAgKSkJxcXF0jKHw4Hi4mKX/1u+mtFodKkHgKKiok7rBwohBObPn4933nkHe/fuRXx8vNf7sNvtOHHiBKKjo29AC32joaEBX3zxRafvyV/PB6d169Zh2LBhSEtL82o7fzwXACA+Ph56vd7l39xms8FsNnf6b96TvzMDgTMsnT59Gu+//z4iIyO93oen36+B6KuvvkJNTU2n78lfz4er/e1vf0NSUhLGjRvn9bY9Oid6NWScum3Tpk1CqVSK9evXi/LycpGbmyu0Wq2wWCxCCCEeeeQR8eSTT0r1Bw8eFMHBweLFF18Un376qcjPzxchISHixIkTvnoLfeKXv/yl0Gg0Yv/+/eLChQvS49KlS1LNtcfi6aefFu+995744osvRGlpqZg1a5ZQqVTi1KlTvngLfeLxxx8X+/fvF5WVleLgwYPCZDKJqKgocfHiRSFE4JwPQnR8c+fWW28Vixcvvm6dP58L9fX14tixY+LYsWMCgPiv//ovcezYMenbX88//7zQarVi+/bt4vjx42L69OkiPj5eNDU1Sfv44Q9/KFavXi099/R3pj/q6ji0traKH//4x+KWW24RH3/8scvfjJaWFmkf1x4HT79f/VFXx6G+vl488cQToqSkRFRWVor3339f3H333SIhIUE0NzdL+/CH80EIz78bQghhtVpFWFiYeOWVV9zu40acEwxMN9Hq1avFrbfeKhQKhUhOThYfffSRtC4lJUVkZWW51G/ZskWMHDlSKBQKMXbsWLFz586b3OK+B8DtY926dVLNtcdi4cKF0nHT6XRi2rRpoqys7OY3vg/NnDlTREdHC4VCIYYPHy5mzpwpzpw5I60PlPNBCCHee+89AUBUVFRct86fz4V9+/a5/V1wvl+HwyGWLl0qdDqdUCqVYvLkydcdo7i4OJGfn++yrKu/M/1RV8ehsrKy078Z+/btk/Zx7XHw9PvVH3V1HC5duiSmTJkihg4dKkJCQkRcXJyYM2fOdcHHH84HITz/bgghxNq1a0VoaKioq6tzu48bcU7IhBDC674sIiIiogDCMUxEREREHjAwEREREXnAwERERETkAQMTERERkQcMTEREREQeMDARERERecDAREREROQBAxMRERGRBwxMRERERB4wMBERERF5wMBERERE5AEDExEREZEH/x+ZOXh20Q+79wAAAABJRU5ErkJggg==\n"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"test_dataloader = DataLoader(test_data, batch_size=train_batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:19.742431Z","iopub.execute_input":"2025-01-12T07:00:19.742758Z","iopub.status.idle":"2025-01-12T07:00:19.746810Z","shell.execute_reply.started":"2025-01-12T07:00:19.742730Z","shell.execute_reply":"2025-01-12T07:00:19.745892Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"evaluate(classification_bert, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T07:00:42.640613Z","iopub.execute_input":"2025-01-12T07:00:42.640913Z","iopub.status.idle":"2025-01-12T07:02:17.576864Z","shell.execute_reply.started":"2025-01-12T07:00:42.640891Z","shell.execute_reply":"2025-01-12T07:02:17.576035Z"}},"outputs":[{"name":"stdout","text":"accuracy:  tensor(0.8102, device='cuda:0')\n","output_type":"stream"},{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"tensor(0.8102, device='cuda:0')"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}