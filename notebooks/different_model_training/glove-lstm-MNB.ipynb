{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":4243451,"sourceType":"datasetVersion","datasetId":32526},{"sourceId":10397748,"sourceType":"datasetVersion","datasetId":6442549},{"sourceId":10609503,"sourceType":"datasetVersion","datasetId":6567983},{"sourceId":10609808,"sourceType":"datasetVersion","datasetId":6568210},{"sourceId":10610363,"sourceType":"datasetVersion","datasetId":6568631}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"STATISTICA AMONG RUMS WILL BE COLLECTED IN CSV FILE\n\n\nMETRIC TRACKING WILL BE DONE ON TOP OF IT","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nstat_file = pd.DataFrame({'model':[],\n                  'model_params':[],\n                  'opt_params':[],\n                  'run_number':[],\n                  'epoch':[],\n                  'validation_or_train':[],\n                  'accuracy':[],\n                  'loss':[],\n                'additional_info':[]})\nstat_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:05:35.733018Z","iopub.execute_input":"2025-01-29T16:05:35.733301Z","iopub.status.idle":"2025-01-29T16:05:35.741943Z","shell.execute_reply.started":"2025-01-29T16:05:35.733277Z","shell.execute_reply":"2025-01-29T16:05:35.741132Z"}},"outputs":[{"execution_count":211,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [model, model_params, opt_params, run_number, epoch, validation_or_train, accuracy, loss, additional_info]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>model_params</th>\n      <th>opt_params</th>\n      <th>run_number</th>\n      <th>epoch</th>\n      <th>validation_or_train</th>\n      <th>accuracy</th>\n      <th>loss</th>\n      <th>additional_info</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":211},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.693305Z","iopub.status.idle":"2025-01-29T15:24:45.693678Z","shell.execute_reply":"2025-01-29T15:24:45.693507Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport torch\nimport pandas as pd\nfrom torch.utils.data import Dataset\nimport re \nimport torch.nn as nn\nclass NewsDataset(Dataset):\n\n    def __preprocess(self, data):\n        data = data.fillna('absent')\n        \n        data.headline[data['headline'].apply(len) == 0] = 'absent'\n        data.link[data['link'].apply(len) == 0] = 'absent'\n        data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n        data.authors[data['authors'].apply(len) == 0] = 'absent'\n        return data\n        \n    def __init__(self, path):\n        \"\"\"_summary_\n\n        Args:\n            path (str): path to .json file\n        \"\"\"\n        j=pd.read_json(path, lines=True)\n        j=self.__preprocess(j)\n        \n        link = j['link'].str.lower().replace(r'\\b(www|http|https|com|html)\\b',' ', regex=True)\n\n        \n        link = link.apply(lambda l: re.sub('[^a-z A-Z 0-9]+', ' ',l ))\n\n        \n        self.x = 'headline: ' +  j['headline'] + \\\n        ' ; short_description: ' + j['short_description'] + \\\n        ' ; authors: ' + j['authors'] + \\\n        ' ; link: ' + link\n\n        \n        self.y = j['category'].astype('category').cat.codes\n        \n    def __len__(self):\n        return len(self.x)\n\n    def __getitem__(self, idx):\n        \"\"\"\n\n        Args:\n            idx (list): _description_\n\n        Returns:\n            str: single item\n        \"\"\"\n        return {'x':self.x.iloc[idx],'y':self.y.iloc[idx]}\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.694466Z","iopub.status.idle":"2025-01-29T15:24:45.694865Z","shell.execute_reply":"2025-01-29T15:24:45.694682Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gensim\nimport numpy as np\nfrom gensim.models import KeyedVectors\nfrom gensim.utils import tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.695555Z","iopub.status.idle":"2025-01-29T15:24:45.695954Z","shell.execute_reply":"2025-01-29T15:24:45.695786Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"embs = KeyedVectors.load_word2vec_format(\"/kaggle/input/google-glove/GoogleNews-vectors-negative300.bin\", binary=True)\nidx = embs.add_vector('unknowntoken',np.random.uniform(0,1,size=300))\nidx = embs.add_vector('padtoken',np.random.uniform(0,1,size=300))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:55:58.517212Z","iopub.execute_input":"2025-01-29T15:55:58.517485Z","iopub.status.idle":"2025-01-29T15:56:25.968155Z","shell.execute_reply.started":"2025-01-29T15:55:58.517462Z","shell.execute_reply":"2025-01-29T15:56:25.967205Z"}},"outputs":[],"execution_count":165},{"cell_type":"code","source":"embs.key_to_index['padtoken']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:25.969199Z","iopub.execute_input":"2025-01-29T15:56:25.969432Z","iopub.status.idle":"2025-01-29T15:56:25.974118Z","shell.execute_reply.started":"2025-01-29T15:56:25.969412Z","shell.execute_reply":"2025-01-29T15:56:25.973294Z"}},"outputs":[{"execution_count":166,"output_type":"execute_result","data":{"text/plain":"3000001"},"metadata":{}}],"execution_count":166},{"cell_type":"code","source":"len(embs.key_to_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:25.975466Z","iopub.execute_input":"2025-01-29T15:56:25.975687Z","iopub.status.idle":"2025-01-29T15:56:25.990710Z","shell.execute_reply.started":"2025-01-29T15:56:25.975667Z","shell.execute_reply":"2025-01-29T15:56:25.990020Z"}},"outputs":[{"execution_count":167,"output_type":"execute_result","data":{"text/plain":"3000002"},"metadata":{}}],"execution_count":167},{"cell_type":"code","source":"embs[500].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:25.991764Z","iopub.execute_input":"2025-01-29T15:56:25.991956Z","iopub.status.idle":"2025-01-29T15:56:26.005365Z","shell.execute_reply.started":"2025-01-29T15:56:25.991939Z","shell.execute_reply":"2025-01-29T15:56:26.004759Z"}},"outputs":[{"execution_count":168,"output_type":"execute_result","data":{"text/plain":"(300,)"},"metadata":{}}],"execution_count":168},{"cell_type":"code","source":"import gensim\nimport numpy as np\nfrom gensim.models import KeyedVectors\nfrom gensim.utils import tokenize","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.006087Z","iopub.execute_input":"2025-01-29T15:56:26.006357Z","iopub.status.idle":"2025-01-29T15:56:26.019249Z","shell.execute_reply.started":"2025-01-29T15:56:26.006329Z","shell.execute_reply":"2025-01-29T15:56:26.018373Z"}},"outputs":[],"execution_count":169},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.020034Z","iopub.execute_input":"2025-01-29T15:56:26.020268Z","iopub.status.idle":"2025-01-29T15:56:26.034238Z","shell.execute_reply.started":"2025-01-29T15:56:26.020249Z","shell.execute_reply":"2025-01-29T15:56:26.033227Z"}},"outputs":[],"execution_count":170},{"cell_type":"code","source":"class TokenizerAsWord2Vec():\n    def __init__(self, keyed_vectors, padding=True, padtoken_idx=3000001):\n        self.padtoken_idx=padtoken_idx\n        self.keyed_vectors=keyed_vectors\n        self.word_to_index = keyed_vectors.key_to_index\n        self.splitter = tokenize\n\n    def forward(self, x):\n        \"\"\"\n        x - (B, L)\n        \"\"\"\n        splitted= []\n        for el in x:\n            splitted.append(self.splitter(el))\n\n\n        tokenized = []\n        for s in splitted:\n            s = list(s)\n            for idx in range(len(s)):\n                if s[idx] not in self.word_to_index:\n                    s[idx]='unknowntoken'\n            sentence=[]\n            for el in s:\n                \n                sentence.append(self.word_to_index[el])\n            tokenized.append(sentence)\n\n        tensors=[]\n        for sent in tokenized:\n            sent = torch.tensor(sent)\n            tensors.append(sent)\n        tensors=pad_sequence(tensors, padding_value=self.padtoken_idx, batch_first=True)\n\n        return tensors\n                ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.035007Z","iopub.execute_input":"2025-01-29T15:56:26.035269Z","iopub.status.idle":"2025-01-29T15:56:26.045084Z","shell.execute_reply.started":"2025-01-29T15:56:26.035243Z","shell.execute_reply":"2025-01-29T15:56:26.044200Z"}},"outputs":[],"execution_count":171},{"cell_type":"code","source":"tokenizer = TokenizerAsWord2Vec(embs, padtoken_idx=embs.key_to_index['padtoken'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.047587Z","iopub.execute_input":"2025-01-29T15:56:26.047891Z","iopub.status.idle":"2025-01-29T15:56:26.063618Z","shell.execute_reply.started":"2025-01-29T15:56:26.047870Z","shell.execute_reply":"2025-01-29T15:56:26.062793Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"tokenizer.forward([\"AASC dsvbhj! fv\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.064871Z","iopub.execute_input":"2025-01-29T15:56:26.065195Z","iopub.status.idle":"2025-01-29T15:56:26.079530Z","shell.execute_reply.started":"2025-01-29T15:56:26.065164Z","shell.execute_reply":"2025-01-29T15:56:26.078502Z"}},"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"tensor([[ 623846, 3000000, 3000000]])"},"metadata":{}}],"execution_count":173},{"cell_type":"code","source":"class LSTMForClassificatoin(nn.Module):\n    def __init__(self,vocab_size, emb_dim,bidirectional,  hidden_size_lstm, num_layers, hiddem_size_MLP, num_classes):\n        super().__init__()\n        self.bidirectional = bidirectional\n        self.embs = nn.Embedding(vocab_size, emb_dim)\n        self.lstm = nn.LSTM(emb_dim, hidden_size_lstm, num_layers, batch_first=True,bidirectional=bidirectional)\n        if bidirectional:\n            self.linear_up = nn.Linear(hidden_size_lstm * 2, hiddem_size_MLP)\n        else:\n            self.linear_up = nn.Linear(hidden_size_lstm, hiddem_size_MLP)\n        self.activation = nn.ReLU()\n        self.linear_down = nn.Linear(hiddem_size_MLP, num_classes)\n\n    def forward(self, x):\n        \"\"\"\n        x - batched tokens\n        Reurns:\n            logits for classes\n        \"\"\"\n        emb = self.embs(x)\n        output, _ = self.lstm(emb)\n        if self.bidirectional:\n            lin1 = self.linear_up(output[:,-1,:] + output[:,0,:] )\n        else:\n            lin1 = self.linear_up(output[:,-1,:] )\n        lin1 = self.activation(lin1)\n        out = self.linear_down(lin1)\n\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.080247Z","iopub.execute_input":"2025-01-29T15:56:26.080475Z","iopub.status.idle":"2025-01-29T15:56:26.095558Z","shell.execute_reply.started":"2025-01-29T15:56:26.080456Z","shell.execute_reply":"2025-01-29T15:56:26.094884Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_batch_size=32\neval_batch_size = 200\naccumulation_steps = 150\n\ntrain_test_split = [0.8, 0.2]\nval_test_split = [0.5, 0.5]\nepochs = 100","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:26.096419Z","iopub.execute_input":"2025-01-29T15:56:26.096744Z","iopub.status.idle":"2025-01-29T15:56:26.113009Z","shell.execute_reply.started":"2025-01-29T15:56:26.096713Z","shell.execute_reply":"2025-01-29T15:56:26.112273Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"\nfrom torch.utils.data import DataLoader\nds = NewsDataset('/kaggle/input/news-category-dataset/News_Category_Dataset_v3.json')\nfrom torch.utils.data import Dataset, DataLoader\ngenerator = torch.Generator().manual_seed(42)\ntrain_data, test_data = torch.utils.data.random_split(ds, train_test_split,generator=generator)\nval_data, test_data = torch.utils.data.random_split(test_data, val_test_split,generator=generator)\n\ntrain_dataloader = DataLoader(train_data, batch_size=train_batch_size,\n                        shuffle=True, num_workers=0)\nval_dataloader = DataLoader(val_data, batch_size=eval_batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2025-01-29T15:56:26.113776Z","iopub.execute_input":"2025-01-29T15:56:26.113991Z","iopub.status.idle":"2025-01-29T15:56:30.299665Z","shell.execute_reply.started":"2025-01-29T15:56:26.113973Z","shell.execute_reply":"2025-01-29T15:56:30.298810Z"},"trusted":true},"outputs":[{"name":"stderr","text":"<ipython-input-88-a90188d8aeda>:11: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.headline[data['headline'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:11: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.headline[data['headline'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:12: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.link[data['link'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.link[data['link'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:13: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.short_description[data['short_description'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:14: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\nYou are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\nA typical example is when you are setting values in a column of a DataFrame, like:\n\ndf[\"col\"][row_indexer] = value\n\nUse `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n  data.authors[data['authors'].apply(len) == 0] = 'absent'\n<ipython-input-88-a90188d8aeda>:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  data.authors[data['authors'].apply(len) == 0] = 'absent'\n","output_type":"stream"}],"execution_count":176},{"cell_type":"code","source":"print('total samples:', len(ds))\nprint('train samples:', len(train_data))\nprint('test samples:', len(test_data))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:30.300408Z","iopub.execute_input":"2025-01-29T15:56:30.300651Z","iopub.status.idle":"2025-01-29T15:56:30.306195Z","shell.execute_reply.started":"2025-01-29T15:56:30.300623Z","shell.execute_reply":"2025-01-29T15:56:30.305526Z"}},"outputs":[{"name":"stdout","text":"total samples: 209527\ntrain samples: 167622\ntest samples: 20952\n","output_type":"stream"}],"execution_count":177},{"cell_type":"code","source":"device = 'cuda:0'if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"execution":{"iopub.status.busy":"2025-01-29T15:56:30.306886Z","iopub.execute_input":"2025-01-29T15:56:30.307100Z","iopub.status.idle":"2025-01-29T15:56:30.323272Z","shell.execute_reply.started":"2025-01-29T15:56:30.307081Z","shell.execute_reply":"2025-01-29T15:56:30.322619Z"},"trusted":true},"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"'cuda:0'"},"metadata":{}}],"execution_count":178},{"cell_type":"code","source":"def get_n_params(model):\n    pp=0\n    for p in list(model.named_parameters()):\n        nn=1\n        for s in list(p[1].size()):\n            nn = nn*s\n        pp += nn\n        print(p[0])\n        print(nn)\n    return pp","metadata":{"execution":{"iopub.status.busy":"2025-01-29T15:56:30.324061Z","iopub.execute_input":"2025-01-29T15:56:30.324294Z","iopub.status.idle":"2025-01-29T15:56:30.336456Z","shell.execute_reply.started":"2025-01-29T15:56:30.324264Z","shell.execute_reply":"2025-01-29T15:56:30.335774Z"},"trusted":true},"outputs":[],"execution_count":179},{"cell_type":"code","source":"def evaluate(model, test_dataloader):\n    with torch.no_grad():\n            matches=0\n            number_of_iters = 0\n            for b_eval in test_dataloader:\n                tokenized = tokenizer.forward(b_eval['x'])\n                \n                preds = model(tokenized.to(device))\n                loss = criterion(preds, b_eval['y'].long().to(device))\n                matches += torch.sum(torch.isclose(b_eval['y'].long().to(device), torch.argmax(preds, dim=1)))\n\n            accuracy = matches / len(test_dataloader.dataset)\n            print('accuracy: ', accuracy, 'loss',loss)\n    return accuracy, loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.715267Z","iopub.status.idle":"2025-01-29T15:24:45.715626Z","shell.execute_reply":"2025-01-29T15:24:45.715467Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"LRs=[]\nepoch_loss = []\nepoch_acc_train=[]\nepoch_acc_test=[]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.716547Z","iopub.status.idle":"2025-01-29T15:24:45.716968Z","shell.execute_reply":"2025-01-29T15:24:45.716775Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_params = {'vocab_size':400002,\n              'emb_dim':50,\n              'hidden_size_lstm':256,\n              'num_layers':3,\n               'hiddem_size_MLP':1024,\n               'num_classes':42,\n               'bidirectional':True}\nmodel = LSTMForClassificatoin(vocab_size=model_params['vocab_size'],\n                          emb_dim=model_params['emb_dim'],\n                          hidden_size_lstm=model_params['hidden_size_lstm'],\n                          num_layers=model_params['num_layers'],\n                          hiddem_size_MLP=model_params['hiddem_size_MLP'],\n                          num_classes=model_params['num_classes'],\n                          bidirectional=model_params['bidirectional'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.717985Z","iopub.status.idle":"2025-01-29T15:24:45.718352Z","shell.execute_reply":"2025-01-29T15:24:45.718190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.embs.weight.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.719059Z","iopub.status.idle":"2025-01-29T15:24:45.719420Z","shell.execute_reply":"2025-01-29T15:24:45.719259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.720110Z","iopub.status.idle":"2025-01-29T15:24:45.720472Z","shell.execute_reply":"2025-01-29T15:24:45.720312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def insert_row(df, row):\n    return pd.concat([df, row], ignore_index=True)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.721132Z","iopub.status.idle":"2025-01-29T15:24:45.721491Z","shell.execute_reply":"2025-01-29T15:24:45.721332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_number=0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.722285Z","iopub.status.idle":"2025-01-29T15:24:45.722656Z","shell.execute_reply":"2025-01-29T15:24:45.722487Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_number+=1\ndef train(model, epochs, optimizer, criterion, scheduler, callback, callback_freq, additional_info):\n    global stat_file\n    for epoch_num in range(1,epochs):\n        \n        accuracies_test=  []\n        accuracies_train=  []\n        losses=[]\n        \n        ttl_loss=0\n        train_iters=0\n        for i, train_batch in enumerate(train_dataloader):\n            \n            # Tokenize and pad\n            tokenized = tokenizer.forward(train_batch['x'])\n            \n\n            preds = model(tokenized.to(device))\n            loss = criterion(preds, train_batch['y'].long().to(device))\n            \n            ttl_loss+=loss.item()\n            train_iters+=1\n            \n            loss.backward()\n            \n            \n            if (i+1) % accumulation_steps == 0:             # Wait for several backward steps\n                optimizer.step()                            # Now we can do an optimizer step\n                model.zero_grad()\n                \n                print('loss', ttl_loss / train_iters)\n                losses.append(ttl_loss / train_iters)\n            \n                \n                ttl_loss=0\n                train_iters=0\n                \n                \n                train_accuracy = torch.sum(torch.isclose(train_batch['y'].long().to(device), torch.argmax(preds, dim=1))) / train_batch_size\n                accuracies_train.append(train_accuracy)\n                print('train accuracy: ',train_accuracy )\n                \n                row = {'model': model.__class__,\n                  'model_params':str(model_params),\n                  'opt_params':str(optimizer_params),\n                  'run_number':run_number,\n                  'epoch':epoch_num,\n                  'validation_or_train':'train',\n                  'accuracy':train_accuracy,\n                  'loss':losses[-1],\n                    'additional_info':additional_info}\n\n                stat_file = insert_row(stat_file, pd.DataFrame(row, index=[len(stat_file)]))\n                \n            del preds\n            del tokenized\n            del loss\n    \n        scheduler.step()\n        \n        print('epoch ',str(epoch_num),'lr', scheduler.get_last_lr())\n        LRs.append(scheduler.get_last_lr())\n\n        if epoch_num % callback_freq == 0:\n            val_acc, loss_val = callback(model, val_dataloader)\n            epoch_acc_test.append(val_acc)\n            print('accuracy: ', val_acc)\n            row = {'model': model.__class__,\n                  'model_params':str(model_params),\n                  'opt_params':str(optimizer_params),\n                  'run_number':run_number,\n                  'epoch':epoch_num,\n                  'validation_or_train':'validation',\n                  'accuracy':val_acc,\n                  'loss':loss_val,\n                  'additional_info':additional_info}\n\n            stat_file = insert_row(stat_file, pd.DataFrame(row, index=[len(stat_file)]))\n        \n        \n        epoch_acc_train.append(accuracies_train)\n        epoch_loss.append(losses)\n        torch.save(model.state_dict(), 'weights'+str(epoch_num)+str(model.__class__)+'.pt')\n\n    return stat_file","metadata":{"execution":{"iopub.status.busy":"2025-01-29T15:24:45.723327Z","iopub.status.idle":"2025-01-29T15:24:45.723716Z","shell.execute_reply":"2025-01-29T15:24:45.723529Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer_params = {'lr':0.00035, 'step_size':10, 'gamma':0.1}\ncallback_freq = 1\nepochs = 20\noptimizer = torch.optim.Adam(model.parameters(), lr=optimizer_params['lr'])\ncriterion = nn.CrossEntropyLoss()\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                            step_size=optimizer_params['step_size'],\n                                            gamma=optimizer_params['gamma'])\n\n\ntrain(model=model,\n      epochs=epochs,\n      optimizer=optimizer,\n      criterion=criterion,\n      scheduler=scheduler,\n      callback=evaluate,\n      callback_freq=1,\n     additional_info='glove pretrained ; not frozen')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.724476Z","iopub.status.idle":"2025-01-29T15:24:45.724895Z","shell.execute_reply":"2025-01-29T15:24:45.724725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stat_file.to_csv('glove_lstm.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.725581Z","iopub.status.idle":"2025-01-29T15:24:45.725994Z","shell.execute_reply":"2025-01-29T15:24:45.725825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_parameter_ratios(model):\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    ratio = trainable_params / total_params\n    return trainable_params, total_params, ratio\n\n# Usage\ntrainable_params, total_params, ratio = get_parameter_ratios(classification_bert)\nprint(f\"Trainable Parameters: {trainable_params}\")\nprint(f\"Total Parameters: {total_params}\")\nprint(f\"Ratio: {ratio:.2%}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-01-29T15:24:45.727059Z","iopub.status.idle":"2025-01-29T15:24:45.728071Z","shell.execute_reply":"2025-01-29T15:24:45.727867Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_test_epoch = [a.cpu() for a in epoch_acc_test]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.728997Z","iopub.status.idle":"2025-01-29T15:24:45.729384Z","shell.execute_reply":"2025-01-29T15:24:45.729213Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_train_epoch = []\nfor a in epoch_acc_train:\n    acc_train_epoch.append([b.cpu() for b in a ])\nacc_train_epoch = np.array(acc_train_epoch).mean(axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.730166Z","iopub.status.idle":"2025-01-29T15:24:45.730543Z","shell.execute_reply":"2025-01-29T15:24:45.730380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc_train_epoch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.731341Z","iopub.status.idle":"2025-01-29T15:24:45.731742Z","shell.execute_reply":"2025-01-29T15:24:45.731546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, ax = plt.subplots(1)\nax.plot(np.arange(len(acc_test_epoch)), acc_test_epoch, label='test')\nax.plot(np.arange(len(acc_train_epoch)), acc_train_epoch, label='train')\nplt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.732536Z","iopub.status.idle":"2025-01-29T15:24:45.732933Z","shell.execute_reply":"2025-01-29T15:24:45.732770Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(np.arange(len(LRs)), LRs, label='test')\nplt.legend()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.734051Z","iopub.status.idle":"2025-01-29T15:24:45.734417Z","shell.execute_reply":"2025-01-29T15:24:45.734259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataloader = DataLoader(test_data, batch_size=train_batch_size,\n                        shuffle=True, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.735064Z","iopub.status.idle":"2025-01-29T15:24:45.735432Z","shell.execute_reply":"2025-01-29T15:24:45.735270Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate(classification_bert, test_dataloader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:24:45.736231Z","iopub.status.idle":"2025-01-29T15:24:45.736600Z","shell.execute_reply":"2025-01-29T15:24:45.736437Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"category_to_index = {\n    'ARTS': 0,\n    'ARTS & CULTURE': 1,\n    'BLACK VOICES': 2,\n    'BUSINESS': 3,\n    'COLLEGE': 4,\n    'COMEDY': 5,\n    'CRIME': 6,\n    'CULTURE & ARTS': 7,\n    'DIVORCE': 8,\n    'EDUCATION': 9,\n    'ENTERTAINMENT': 10,\n    'ENVIRONMENT': 11,\n    'FIFTY': 12,\n    'FOOD & DRINK': 13,\n    'GOOD NEWS': 14,\n    'GREEN': 15,\n    'HEALTHY LIVING': 16,\n    'HOME & LIVING': 17,\n    'IMPACT': 18,\n    'LATINO VOICES': 19,\n    'MEDIA': 20,\n    'MONEY': 21,\n    'PARENTING': 22,\n    'PARENTS': 23,\n    'POLITICS': 24,\n    'QUEER VOICES': 25,\n    'RELIGION': 26,\n    'SCIENCE': 27,\n    'SPORTS': 28,\n    'STYLE': 29,\n    'STYLE & BEAUTY': 30,\n    'TASTE': 31,\n    'TECH': 32,\n    'THE WORLDPOST': 33,\n    'TRAVEL': 34,\n    'U.S. NEWS': 35,\n    'WEDDINGS': 36,\n    'WEIRD NEWS': 37,\n    'WELLNESS': 38,\n    'WOMEN': 39,\n    'WORLD NEWS': 40,\n    'WORLDPOST': 41\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:31.425115Z","iopub.execute_input":"2025-01-29T15:56:31.425393Z","iopub.status.idle":"2025-01-29T15:56:31.430678Z","shell.execute_reply.started":"2025-01-29T15:56:31.425370Z","shell.execute_reply":"2025-01-29T15:56:31.429935Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"def convert_all_texts_to_table(tokenizer, embs, train_loader, test_loader, unk_token_idx, pad_token_idx):\n    \n\n    def prepare_one_batch_for_multinomial_NB(embs, batch, unk_token_idx, pad_token_idx):\n        batch = tokenizer.forward(batch['x'])\n        res = []\n        for sent in batch:\n            sent= sent.numpy()\n            \n            sent = sent[(sent!=unk_token_idx) & (sent != pad_token_idx)]\n            sent_pres = embs.get_mean_vector(sent)\n            \n            res.append(sent_pres)\n    \n        return res\n\n    train_features=[]\n    y_train=[]\n    for batch in train_loader:\n        y_train.append([int(el) for el in batch['y']])\n        train_features.append(prepare_one_batch_for_multinomial_NB(embs, batch, unk_token_idx, pad_token_idx))\n        \n    val_features=[]\n    y_test=[]\n    for batch in test_loader:\n        y_test.append([int(el) for el in batch['y']])\n        val_features.append(prepare_one_batch_for_multinomial_NB(embs, batch, unk_token_idx, pad_token_idx))\n\n    return train_features, val_features, y_train, y_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:33.880088Z","iopub.execute_input":"2025-01-29T15:56:33.880370Z","iopub.status.idle":"2025-01-29T15:56:33.886249Z","shell.execute_reply.started":"2025-01-29T15:56:33.880349Z","shell.execute_reply":"2025-01-29T15:56:33.885310Z"}},"outputs":[],"execution_count":181},{"cell_type":"code","source":"train_features, val_features, y_train, y_test = convert_all_texts_to_table(tokenizer,\n                                                         embs,\n                                                         train_dataloader,\n                                                         val_dataloader,\n                                                         embs.key_to_index['unknowntoken'],\n                                                         embs.key_to_index['padtoken'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:56:44.436555Z","iopub.execute_input":"2025-01-29T15:56:44.436864Z","iopub.status.idle":"2025-01-29T15:58:16.057187Z","shell.execute_reply.started":"2025-01-29T15:56:44.436840Z","shell.execute_reply":"2025-01-29T15:58:16.056459Z"}},"outputs":[],"execution_count":182},{"cell_type":"code","source":"train_features = np.array(train_features[:-1])\nval_features = np.array(val_features[:-1])\ny_train = np.array(y_train[:-1])\ny_test = np.array(y_test[:-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:58:16.058211Z","iopub.execute_input":"2025-01-29T15:58:16.058487Z","iopub.status.idle":"2025-01-29T15:58:16.302325Z","shell.execute_reply.started":"2025-01-29T15:58:16.058464Z","shell.execute_reply":"2025-01-29T15:58:16.301365Z"}},"outputs":[],"execution_count":183},{"cell_type":"code","source":"train_features = train_features.reshape(-1,300)\nval_features = val_features.reshape(-1,300)\ny_train = y_train.reshape(-1)\ny_test = y_test.reshape(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:58:16.303780Z","iopub.execute_input":"2025-01-29T15:58:16.304075Z","iopub.status.idle":"2025-01-29T15:58:16.307867Z","shell.execute_reply.started":"2025-01-29T15:58:16.304052Z","shell.execute_reply":"2025-01-29T15:58:16.307093Z"}},"outputs":[],"execution_count":184},{"cell_type":"code","source":"print(val_features.shape)\nprint(y_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:58:16.308983Z","iopub.execute_input":"2025-01-29T15:58:16.309211Z","iopub.status.idle":"2025-01-29T15:58:16.323316Z","shell.execute_reply.started":"2025-01-29T15:58:16.309192Z","shell.execute_reply":"2025-01-29T15:58:16.322479Z"}},"outputs":[{"name":"stdout","text":"(20800, 300)\n(20800,)\n","output_type":"stream"}],"execution_count":185},{"cell_type":"code","source":"from sklearn.metrics import f1_score\ndef train_NB(model, train_features, val_features, y_train, y_test):\n    model.fit(train_features+2, y_train)\n    preds = model.predict(val_features+2)\n    print(f1_score(y_test, preds, average='macro'))\n    return sum(preds == y_test) / len(preds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:05:03.285660Z","iopub.execute_input":"2025-01-29T16:05:03.286060Z","iopub.status.idle":"2025-01-29T16:05:03.290416Z","shell.execute_reply.started":"2025-01-29T16:05:03.286031Z","shell.execute_reply":"2025-01-29T16:05:03.289598Z"}},"outputs":[],"execution_count":207},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nacc = train_NB(nb, train_features, val_features, y_train, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:05:03.905806Z","iopub.execute_input":"2025-01-29T16:05:03.906103Z","iopub.status.idle":"2025-01-29T16:05:04.332142Z","shell.execute_reply.started":"2025-01-29T16:05:03.906077Z","shell.execute_reply":"2025-01-29T16:05:04.331242Z"}},"outputs":[{"name":"stdout","text":"0.006825135325959049\n","output_type":"stream"}],"execution_count":208},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:01:02.073974Z","iopub.execute_input":"2025-01-29T16:01:02.074265Z","iopub.status.idle":"2025-01-29T16:01:02.079182Z","shell.execute_reply.started":"2025-01-29T16:01:02.074243Z","shell.execute_reply":"2025-01-29T16:01:02.078308Z"}},"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"0.1673076923076923"},"metadata":{}}],"execution_count":198},{"cell_type":"code","source":"row = {'model': nb.__class__,\n                  'model_params':None,\n                  'opt_params':None,\n                  'run_number':None,\n                  'epoch':None,\n                  'validation_or_train':'validation',\n                  'accuracy':acc,\n                  'loss':None,\n                  'additional_info':'multinomial NB - 0.006825135325959049 F1 score'}\n\nstat_file = insert_row(stat_file, pd.DataFrame(row, index=[len(stat_file)]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:05:42.790272Z","iopub.execute_input":"2025-01-29T16:05:42.790583Z","iopub.status.idle":"2025-01-29T16:05:42.796231Z","shell.execute_reply.started":"2025-01-29T16:05:42.790555Z","shell.execute_reply":"2025-01-29T16:05:42.795363Z"}},"outputs":[],"execution_count":212},{"cell_type":"code","source":"stat_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T16:05:43.347848Z","iopub.execute_input":"2025-01-29T16:05:43.348130Z","iopub.status.idle":"2025-01-29T16:05:43.357909Z","shell.execute_reply.started":"2025-01-29T16:05:43.348106Z","shell.execute_reply":"2025-01-29T16:05:43.357189Z"}},"outputs":[{"execution_count":213,"output_type":"execute_result","data":{"text/plain":"                                         model model_params opt_params  \\\n0  <class 'sklearn.naive_bayes.MultinomialNB'>         None       None   \n\n  run_number epoch validation_or_train  accuracy  loss  \\\n0       None  None          validation  0.167308  None   \n\n                                  additional_info  \n0  multinomial NB - 0.006825135325959049 F1 score  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>model_params</th>\n      <th>opt_params</th>\n      <th>run_number</th>\n      <th>epoch</th>\n      <th>validation_or_train</th>\n      <th>accuracy</th>\n      <th>loss</th>\n      <th>additional_info</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;class 'sklearn.naive_bayes.MultinomialNB'&gt;</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>None</td>\n      <td>validation</td>\n      <td>0.167308</td>\n      <td>None</td>\n      <td>multinomial NB - 0.006825135325959049 F1 score</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":213},{"cell_type":"code","source":"stat_file.to_csv('glove-MNB.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T15:58:41.109235Z","iopub.execute_input":"2025-01-29T15:58:41.109576Z","iopub.status.idle":"2025-01-29T15:58:41.114687Z","shell.execute_reply.started":"2025-01-29T15:58:41.109539Z","shell.execute_reply":"2025-01-29T15:58:41.113922Z"}},"outputs":[],"execution_count":190},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}